{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3788ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ec7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "WARNING:tensorflow:From C:\\Users\\dujy0\\AppData\\Local\\Temp\\ipykernel_30096\\4004085722.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "\n",
      "CUDA GPU: False\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB=True\n",
    "except:\n",
    "    IN_COLAB=False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"We're running Colab\")\n",
    "else:\n",
    "    print(tf.config.list_physical_devices())\n",
    "    print('\\nCUDA GPU: ' + str(tf.test.is_gpu_available(cuda_only=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ebbfa",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825068e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "df = pd.read_csv('./hourly02-ithaca/hourly02-NY_Ithaca_13_E.csv', header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa511986",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = pd.to_datetime(df.UTC_DATE, format='%Y%m%d', errors='coerce')\n",
    "+ pd.to_timedelta(df.UTC_TIME//100, unit = 'hours')\n",
    "df['Time'] = Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4cc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['T_CALC', 'T_HR_AVG', 'T_MAX', 'T_MIN',\n",
    "       'P_CALC', 'SOLARAD', 'SOLARAD_MAX',\n",
    "       'SOLARAD_MIN', 'SUR_TEMP',\n",
    "           'SUR_TEMP_MAX', 'SUR_TEMP_MIN', 'RH_HR_AVG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8058f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba2a471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_CALC</th>\n",
       "      <th>T_HR_AVG</th>\n",
       "      <th>T_MAX</th>\n",
       "      <th>T_MIN</th>\n",
       "      <th>P_CALC</th>\n",
       "      <th>SOLARAD</th>\n",
       "      <th>SOLARAD_MAX</th>\n",
       "      <th>SOLARAD_MIN</th>\n",
       "      <th>SUR_TEMP</th>\n",
       "      <th>SUR_TEMP_MAX</th>\n",
       "      <th>SUR_TEMP_MIN</th>\n",
       "      <th>RH_HR_AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-10-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>7.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>5.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166759 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            T_CALC  T_HR_AVG  T_MAX  T_MIN  P_CALC  SOLARAD  SOLARAD_MAX  \\\n",
       "Time                                                                       \n",
       "2004-10-27     NaN       NaN    NaN    NaN     NaN     27.0          NaN   \n",
       "2004-10-27     NaN       NaN    NaN    NaN     NaN      0.0          NaN   \n",
       "2004-10-28     7.8       7.6    8.0    7.3     0.0      0.0          NaN   \n",
       "2004-10-28     6.5       7.0    7.8    6.5     0.0      0.0          NaN   \n",
       "2004-10-28     5.4       6.2    6.5    5.4     0.0      0.0          NaN   \n",
       "...            ...       ...    ...    ...     ...      ...          ...   \n",
       "2023-11-06     1.1       1.3    2.1    0.3     0.0      0.0          0.0   \n",
       "2023-11-06    -0.1       0.0    1.0   -1.1     0.0      0.0          0.0   \n",
       "2023-11-06    -0.5      -0.4    0.1   -0.7     0.0      0.0          0.0   \n",
       "2023-11-06    -1.4      -1.3   -0.5   -1.7     0.0      0.0          0.0   \n",
       "2023-11-06    -1.9      -1.6   -1.4   -2.2     0.0      0.0          0.0   \n",
       "\n",
       "            SOLARAD_MIN  SUR_TEMP  SUR_TEMP_MAX  SUR_TEMP_MIN  RH_HR_AVG  \n",
       "Time                                                                      \n",
       "2004-10-27          NaN       8.8           NaN           NaN        0.0  \n",
       "2004-10-27          NaN       6.7           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       6.1           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       5.6           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       5.0           NaN           NaN        0.0  \n",
       "...                 ...       ...           ...           ...        ...  \n",
       "2023-11-06          0.0      -1.6          -0.9          -2.0       76.0  \n",
       "2023-11-06          0.0      -2.3          -1.9          -2.8       80.0  \n",
       "2023-11-06          0.0      -3.1          -2.8          -3.3       83.0  \n",
       "2023-11-06          0.0      -3.2          -2.8          -3.5       85.0  \n",
       "2023-11-06          0.0      -3.5          -3.3          -3.8       87.0  \n",
       "\n",
       "[166759 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b1a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_CALC           1384\n",
       "T_HR_AVG         1446\n",
       "T_MAX            1385\n",
       "T_MIN            1389\n",
       "P_CALC            832\n",
       "SOLARAD           570\n",
       "SOLARAD_MAX      9757\n",
       "SOLARAD_MIN      9757\n",
       "SUR_TEMP          724\n",
       "SUR_TEMP_MAX     9911\n",
       "SUR_TEMP_MIN     9911\n",
       "RH_HR_AVG       48248\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98be58ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166759, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0d169f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill the missing values  \n",
    "data.ffill(axis = 0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cbbdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN at the top\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ba21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target\n",
    "data['target'] = data['T_HR_AVG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6a51031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "597b6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "with open('./LSTM/models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba1ac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126057, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf181b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31515, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99ce69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into sequences\n",
    "def split_sequences(features, target, seq_len, forecast_len):\n",
    "    X,y = list(), list()\n",
    "    for i in range(len(features)):\n",
    "        end_input = i + seq_len\n",
    "        end_predict = end_input + forecast_len\n",
    "        if end_predict > len(features)-1:\n",
    "            break\n",
    "        seq_x, seq_y = features[i:end_input,:], target[end_input:end_predict]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return tf.convert_to_tensor(X, dtype=tf.float64), tf.convert_to_tensor(y, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc7e6b",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e46daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RNN, LSTMCell, Input, Bidirectional\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape, name = 'LSTM'):\n",
    "        super().__init__(name = name)\n",
    "        self.input_layer = Input(shape = input_shape, name = 'input')\n",
    "        self.lstm1 = LSTM(units=30, activation = 'tanh', input_shape = input_shape, return_sequences=False, name = 'lstm_1')\n",
    "        self.dense1 = Dense(units=output_shape, activation = 'sigmoid', name = 'dense_1')\n",
    "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.lstm1(inputs)\n",
    "        x = self.dense1(x)\n",
    "        #if training:\n",
    "        #  x = self.dropout(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def summary(self):\n",
    "        model = Model(inputs = [self.input_layer], outputs = self.call(self.input_layer), name = self.name)\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28807bc6",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "## input length : output length = 16:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03ec4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequences\n",
    "seq_len = 16\n",
    "forecast_len = 4\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c26eaa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([126037, 16, 12])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "039bed2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([126037, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f03c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_16-4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 16, 12)]          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30)                5160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 124       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,284\n",
      "Trainable params: 5,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'LSTM_16-4'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06942327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 6s 4ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5543 - val_loss: 6.1432e-04 - val_mse: 6.1432e-04 - val_acc: 0.5943\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 5s 4ms/step - loss: 6.0231e-04 - mse: 6.0231e-04 - acc: 0.6231 - val_loss: 6.2510e-04 - val_mse: 6.2510e-04 - val_acc: 0.6020\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 5.5510e-04 - mse: 5.5510e-04 - acc: 0.6421 - val_loss: 4.7013e-04 - val_mse: 4.7013e-04 - val_acc: 0.6230\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 5.2295e-04 - mse: 5.2295e-04 - acc: 0.6499 - val_loss: 4.7638e-04 - val_mse: 4.7638e-04 - val_acc: 0.6292\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 5.0851e-04 - mse: 5.0851e-04 - acc: 0.6504 - val_loss: 4.5760e-04 - val_mse: 4.5760e-04 - val_acc: 0.6495\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 5s 4ms/step - loss: 4.9627e-04 - mse: 4.9627e-04 - acc: 0.6550 - val_loss: 4.9104e-04 - val_mse: 4.9104e-04 - val_acc: 0.6573\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 5s 4ms/step - loss: 4.8227e-04 - mse: 4.8227e-04 - acc: 0.6545 - val_loss: 4.5754e-04 - val_mse: 4.5754e-04 - val_acc: 0.6287\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.7850e-04 - mse: 4.7850e-04 - acc: 0.6592 - val_loss: 4.6242e-04 - val_mse: 4.6242e-04 - val_acc: 0.5876\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.7002e-04 - mse: 4.7002e-04 - acc: 0.6602 - val_loss: 4.6861e-04 - val_mse: 4.6861e-04 - val_acc: 0.6455\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.6300e-04 - mse: 4.6300e-04 - acc: 0.6620 - val_loss: 4.3718e-04 - val_mse: 4.3718e-04 - val_acc: 0.5211\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.5947e-04 - mse: 4.5947e-04 - acc: 0.6619 - val_loss: 4.5930e-04 - val_mse: 4.5930e-04 - val_acc: 0.5983\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.5090e-04 - mse: 4.5090e-04 - acc: 0.6626 - val_loss: 4.4036e-04 - val_mse: 4.4036e-04 - val_acc: 0.6540\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.4743e-04 - mse: 4.4743e-04 - acc: 0.6657 - val_loss: 4.2212e-04 - val_mse: 4.2212e-04 - val_acc: 0.6460\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.4374e-04 - mse: 4.4374e-04 - acc: 0.6677 - val_loss: 4.7739e-04 - val_mse: 4.7739e-04 - val_acc: 0.6446\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.3635e-04 - mse: 4.3635e-04 - acc: 0.6666 - val_loss: 4.2124e-04 - val_mse: 4.2124e-04 - val_acc: 0.6515\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.3456e-04 - mse: 4.3456e-04 - acc: 0.6668 - val_loss: 4.4410e-04 - val_mse: 4.4410e-04 - val_acc: 0.6464\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.3317e-04 - mse: 4.3317e-04 - acc: 0.6661 - val_loss: 4.1726e-04 - val_mse: 4.1726e-04 - val_acc: 0.6596\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.2856e-04 - mse: 4.2856e-04 - acc: 0.6681 - val_loss: 4.2614e-04 - val_mse: 4.2614e-04 - val_acc: 0.6487\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.2444e-04 - mse: 4.2444e-04 - acc: 0.6701 - val_loss: 4.2126e-04 - val_mse: 4.2126e-04 - val_acc: 0.6477\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.2309e-04 - mse: 4.2309e-04 - acc: 0.6698 - val_loss: 4.6996e-04 - val_mse: 4.6996e-04 - val_acc: 0.5993\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.2223e-04 - mse: 4.2223e-04 - acc: 0.6692 - val_loss: 4.6242e-04 - val_mse: 4.6242e-04 - val_acc: 0.6249\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.1884e-04 - mse: 4.1884e-04 - acc: 0.6686 - val_loss: 4.3058e-04 - val_mse: 4.3058e-04 - val_acc: 0.6321\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 5s 4ms/step - loss: 4.1698e-04 - mse: 4.1698e-04 - acc: 0.6685 - val_loss: 4.3963e-04 - val_mse: 4.3963e-04 - val_acc: 0.6474\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 5s 4ms/step - loss: 4.1580e-04 - mse: 4.1580e-04 - acc: 0.6684 - val_loss: 4.2807e-04 - val_mse: 4.2807e-04 - val_acc: 0.6487\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 5s 4ms/step - loss: 4.1353e-04 - mse: 4.1353e-04 - acc: 0.6715 - val_loss: 4.4695e-04 - val_mse: 4.4695e-04 - val_acc: 0.6230\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.1203e-04 - mse: 4.1203e-04 - acc: 0.6696 - val_loss: 4.4349e-04 - val_mse: 4.4349e-04 - val_acc: 0.6396\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.1087e-04 - mse: 4.1087e-04 - acc: 0.6708 - val_loss: 4.5315e-04 - val_mse: 4.5315e-04 - val_acc: 0.6411\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.0808e-04 - mse: 4.0808e-04 - acc: 0.6703 - val_loss: 4.7298e-04 - val_mse: 4.7298e-04 - val_acc: 0.6596\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.0844e-04 - mse: 4.0844e-04 - acc: 0.6699 - val_loss: 4.8248e-04 - val_mse: 4.8248e-04 - val_acc: 0.6457\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 4s 4ms/step - loss: 4.0488e-04 - mse: 4.0488e-04 - acc: 0.6702 - val_loss: 4.7926e-04 - val_mse: 4.7926e-04 - val_acc: 0.6479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220ae137700>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceea1dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/LSTM_16-4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/LSTM_16-4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3939/3939 [==============================] - 4s 933us/step\n",
      "985/985 [==============================] - 1s 970us/step\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd0043ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error\n",
      "train set: 0.00042307978852202906\n",
      "test set: 0.0004726246875467533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258ce9b",
   "metadata": {},
   "source": [
    "## input length : output length = 24:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8be2411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 24\n",
    "forecast_len = 6\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "787bb430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_24-6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 24, 12)]          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30)                5160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 186       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,346\n",
      "Trainable params: 5,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'LSTM_24-6'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2e8f948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 8s 6ms/step - loss: 0.0016 - mse: 0.0016 - acc: 0.5383 - val_loss: 9.5024e-04 - val_mse: 9.5024e-04 - val_acc: 0.4986\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 6s 5ms/step - loss: 8.3921e-04 - mse: 8.3921e-04 - acc: 0.5894 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5865\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 6s 5ms/step - loss: 7.7170e-04 - mse: 7.7170e-04 - acc: 0.6005 - val_loss: 7.4368e-04 - val_mse: 7.4368e-04 - val_acc: 0.5683\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 7.3616e-04 - mse: 7.3616e-04 - acc: 0.6079 - val_loss: 7.3590e-04 - val_mse: 7.3590e-04 - val_acc: 0.5300\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 7.1801e-04 - mse: 7.1801e-04 - acc: 0.6106 - val_loss: 7.3873e-04 - val_mse: 7.3873e-04 - val_acc: 0.5916\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 7.0555e-04 - mse: 7.0555e-04 - acc: 0.6165 - val_loss: 7.3497e-04 - val_mse: 7.3497e-04 - val_acc: 0.6083\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.8786e-04 - mse: 6.8786e-04 - acc: 0.6198 - val_loss: 6.8371e-04 - val_mse: 6.8371e-04 - val_acc: 0.5934\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.8155e-04 - mse: 6.8155e-04 - acc: 0.6200 - val_loss: 7.1832e-04 - val_mse: 7.1832e-04 - val_acc: 0.6087\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.6571e-04 - mse: 6.6571e-04 - acc: 0.6206 - val_loss: 7.3339e-04 - val_mse: 7.3339e-04 - val_acc: 0.5506\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.6079e-04 - mse: 6.6079e-04 - acc: 0.6250 - val_loss: 6.9131e-04 - val_mse: 6.9131e-04 - val_acc: 0.5969\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 6.5430e-04 - mse: 6.5430e-04 - acc: 0.6257 - val_loss: 7.4074e-04 - val_mse: 7.4074e-04 - val_acc: 0.5954\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.4762e-04 - mse: 6.4762e-04 - acc: 0.6275 - val_loss: 7.1516e-04 - val_mse: 7.1516e-04 - val_acc: 0.5611\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.3972e-04 - mse: 6.3972e-04 - acc: 0.6285 - val_loss: 6.8505e-04 - val_mse: 6.8505e-04 - val_acc: 0.5949\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.3479e-04 - mse: 6.3479e-04 - acc: 0.6281 - val_loss: 7.2093e-04 - val_mse: 7.2093e-04 - val_acc: 0.5472\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.3115e-04 - mse: 6.3115e-04 - acc: 0.6299 - val_loss: 7.2783e-04 - val_mse: 7.2783e-04 - val_acc: 0.6164\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.2778e-04 - mse: 6.2778e-04 - acc: 0.6277 - val_loss: 8.0221e-04 - val_mse: 8.0221e-04 - val_acc: 0.6071\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.2265e-04 - mse: 6.2265e-04 - acc: 0.6293 - val_loss: 7.4833e-04 - val_mse: 7.4833e-04 - val_acc: 0.6298\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.1890e-04 - mse: 6.1890e-04 - acc: 0.6301 - val_loss: 7.0794e-04 - val_mse: 7.0794e-04 - val_acc: 0.5688\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.1650e-04 - mse: 6.1650e-04 - acc: 0.6294 - val_loss: 7.6338e-04 - val_mse: 7.6338e-04 - val_acc: 0.5797\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.1198e-04 - mse: 6.1198e-04 - acc: 0.6303 - val_loss: 7.3233e-04 - val_mse: 7.3233e-04 - val_acc: 0.5776\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.1173e-04 - mse: 6.1173e-04 - acc: 0.6297 - val_loss: 7.4356e-04 - val_mse: 7.4356e-04 - val_acc: 0.5661\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.0687e-04 - mse: 6.0687e-04 - acc: 0.6287 - val_loss: 7.2140e-04 - val_mse: 7.2140e-04 - val_acc: 0.6111\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 6.0223e-04 - mse: 6.0223e-04 - acc: 0.6305 - val_loss: 7.0165e-04 - val_mse: 7.0165e-04 - val_acc: 0.6151\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 6.0226e-04 - mse: 6.0226e-04 - acc: 0.6315 - val_loss: 7.3911e-04 - val_mse: 7.3911e-04 - val_acc: 0.5953\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 6.0121e-04 - mse: 6.0121e-04 - acc: 0.6304 - val_loss: 7.7904e-04 - val_mse: 7.7904e-04 - val_acc: 0.5967\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 5.9551e-04 - mse: 5.9551e-04 - acc: 0.6310 - val_loss: 7.5016e-04 - val_mse: 7.5016e-04 - val_acc: 0.5937\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 5.9658e-04 - mse: 5.9658e-04 - acc: 0.6311 - val_loss: 7.8866e-04 - val_mse: 7.8866e-04 - val_acc: 0.5931\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 5.9470e-04 - mse: 5.9470e-04 - acc: 0.6316 - val_loss: 7.3145e-04 - val_mse: 7.3145e-04 - val_acc: 0.6233\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 5.9402e-04 - mse: 5.9402e-04 - acc: 0.6306 - val_loss: 7.6517e-04 - val_mse: 7.6517e-04 - val_acc: 0.5680\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 7s 7ms/step - loss: 5.8918e-04 - mse: 5.8918e-04 - acc: 0.6315 - val_loss: 7.5794e-04 - val_mse: 7.5794e-04 - val_acc: 0.6258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220ae84e1a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "520fc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/LSTM_24-6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/LSTM_24-6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3939/3939 [==============================] - 5s 1ms/step\n",
      "984/984 [==============================] - 1s 1ms/step\n",
      "mean_squared_error\n",
      "train set: 0.0005922814113797606\n",
      "test set: 0.0006566592884433023\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)\n",
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dbd001",
   "metadata": {},
   "source": [
    "## input length : output length = 32:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86bc5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 32\n",
    "forecast_len = 8\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab4164d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_32-8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 32, 12)]          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30)                5160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 248       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,408\n",
      "Trainable params: 5,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'LSTM_32-8'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b571424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 9s 7ms/step - loss: 0.0019 - mse: 0.0019 - acc: 0.5018 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5143\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 7s 7ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5452 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5006\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5583 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5437\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5624 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5340\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 9.9623e-04 - mse: 9.9623e-04 - acc: 0.5688 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5177\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 9.8893e-04 - mse: 9.8893e-04 - acc: 0.5681 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.4957\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 9.5388e-04 - mse: 9.5388e-04 - acc: 0.5695 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5332\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 9.4816e-04 - mse: 9.4816e-04 - acc: 0.5702 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5475\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 9.2144e-04 - mse: 9.2144e-04 - acc: 0.5740 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5344\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 9.1480e-04 - mse: 9.1480e-04 - acc: 0.5750 - val_loss: 9.9852e-04 - val_mse: 9.9852e-04 - val_acc: 0.5457\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.9855e-04 - mse: 8.9855e-04 - acc: 0.5721 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5467\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.8693e-04 - mse: 8.8693e-04 - acc: 0.5744 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5394\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.8762e-04 - mse: 8.8762e-04 - acc: 0.5749 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5172\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.7439e-04 - mse: 8.7439e-04 - acc: 0.5763 - val_loss: 9.7498e-04 - val_mse: 9.7498e-04 - val_acc: 0.5625\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.6993e-04 - mse: 8.6993e-04 - acc: 0.5755 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5764\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.5942e-04 - mse: 8.5942e-04 - acc: 0.5762 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5317\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.5757e-04 - mse: 8.5757e-04 - acc: 0.5751 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5415\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.5168e-04 - mse: 8.5168e-04 - acc: 0.5755 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5713\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.4591e-04 - mse: 8.4591e-04 - acc: 0.5764 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5313\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.3880e-04 - mse: 8.3880e-04 - acc: 0.5776 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5233\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.3889e-04 - mse: 8.3889e-04 - acc: 0.5756 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5543\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.3101e-04 - mse: 8.3101e-04 - acc: 0.5778 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5411\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.2749e-04 - mse: 8.2749e-04 - acc: 0.5777 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5802\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.2303e-04 - mse: 8.2303e-04 - acc: 0.5774 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5380\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.1959e-04 - mse: 8.1959e-04 - acc: 0.5778 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5431\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.1562e-04 - mse: 8.1562e-04 - acc: 0.5789 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5513\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.1197e-04 - mse: 8.1197e-04 - acc: 0.5791 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5216\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.0957e-04 - mse: 8.0957e-04 - acc: 0.5816 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5640\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.0969e-04 - mse: 8.0969e-04 - acc: 0.5795 - val_loss: 9.8305e-04 - val_mse: 9.8305e-04 - val_acc: 0.5511\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 8.0331e-04 - mse: 8.0331e-04 - acc: 0.5807 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220e5ad66b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed47bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/LSTM_32-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/LSTM_32-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3939/3939 [==============================] - 6s 1ms/step\n",
      "984/984 [==============================] - 1s 1ms/step\n",
      "mean_squared_error\n",
      "train set: 0.0008411782469462793\n",
      "test set: 0.0009483065049563807\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)\n",
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e0a20",
   "metadata": {},
   "source": [
    "## input length : output length = 40:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c9521fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 40\n",
    "forecast_len = 10\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2091b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_40-10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 40, 12)]          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30)                5160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,470\n",
      "Trainable params: 5,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'LSTM_40-10'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2de6ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 12s 9ms/step - loss: 0.0022 - mse: 0.0022 - acc: 0.4617 - val_loss: 0.0019 - val_mse: 0.0019 - val_acc: 0.4110\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 0.0015 - mse: 0.0015 - acc: 0.5046 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5094\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5187 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.4781\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5267 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4227\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5316 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4953\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5338 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.5176\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5350 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4456\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5340 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5045\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5354 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.4839\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 13s 12ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5376 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5065\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5362 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5101\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5367 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5285\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5371 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5183\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5385 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5121\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5394 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.4937\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5393 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5245\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5396 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5147\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5382 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.4679\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5395 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5015\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5383 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4966\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5387 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5206\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5385 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5042\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5380 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5043\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 9.9412e-04 - mse: 9.9412e-04 - acc: 0.5387 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.4909\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 9.9282e-04 - mse: 9.9282e-04 - acc: 0.5384 - val_loss: 0.0016 - val_mse: 0.0016 - val_acc: 0.4958\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 9.8107e-04 - mse: 9.8107e-04 - acc: 0.5404 - val_loss: 0.0016 - val_mse: 0.0016 - val_acc: 0.5070\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 9.7878e-04 - mse: 9.7878e-04 - acc: 0.5389 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.5154\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 9.7636e-04 - mse: 9.7636e-04 - acc: 0.5392 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.4992\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 9.7418e-04 - mse: 9.7418e-04 - acc: 0.5392 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.4978\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 9.7054e-04 - mse: 9.7054e-04 - acc: 0.5397 - val_loss: 0.0016 - val_mse: 0.0016 - val_acc: 0.5076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220b701e320>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "881a1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/LSTM_40-10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/LSTM_40-10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3938/3938 [==============================] - 6s 2ms/step\n",
      "984/984 [==============================] - 2s 2ms/step\n",
      "mean_squared_error\n",
      "train set: 0.0010020999755895271\n",
      "test set: 0.0010936746550938995\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)\n",
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c5a73-c40f-4b16-bef3-463526a7798f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
