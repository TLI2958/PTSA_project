{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3788ae25",
   "metadata": {
    "id": "3788ae25"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ec7b6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7ec7b6f",
    "outputId": "92a7b146-ae98-4da9-f6ec-5e79a38905e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "WARNING:tensorflow:From C:\\Users\\dujy0\\AppData\\Local\\Temp\\ipykernel_24544\\4004085722.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "\n",
      "CUDA GPU: False\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB=True\n",
    "except:\n",
    "    IN_COLAB=False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"We're running Colab\")\n",
    "else:\n",
    "    print(tf.config.list_physical_devices())\n",
    "    print('\\nCUDA GPU: ' + str(tf.test.is_gpu_available(cuda_only=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ebbfa",
   "metadata": {
    "id": "1f0ebbfa"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825068e6",
   "metadata": {
    "id": "825068e6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "df = pd.read_csv('./daily01-ithaca/daily01-NY_Ithaca_13_E.csv', header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1182c379",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "1182c379",
    "outputId": "3a761207-01e1-4b9a-ac2e-7fe4bd83978e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WBANNO</th>\n",
       "      <th>LST_DATE</th>\n",
       "      <th>CRX_VN</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>T_DAILY_MAX</th>\n",
       "      <th>T_DAILY_MIN</th>\n",
       "      <th>T_DAILY_MEAN</th>\n",
       "      <th>T_DAILY_AVG</th>\n",
       "      <th>P_DAILY_CALC</th>\n",
       "      <th>...</th>\n",
       "      <th>SOIL_MOISTURE_5_DAILY</th>\n",
       "      <th>SOIL_MOISTURE_10_DAILY</th>\n",
       "      <th>SOIL_MOISTURE_20_DAILY</th>\n",
       "      <th>SOIL_MOISTURE_50_DAILY</th>\n",
       "      <th>SOIL_MOISTURE_100_DAILY</th>\n",
       "      <th>SOIL_TEMP_5_DAILY</th>\n",
       "      <th>SOIL_TEMP_10_DAILY</th>\n",
       "      <th>SOIL_TEMP_20_DAILY</th>\n",
       "      <th>SOIL_TEMP_50_DAILY</th>\n",
       "      <th>SOIL_TEMP_100_DAILY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041027</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041028</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>12.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041029</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>16.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041030</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>17.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041031</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231101</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.021</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231102</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.021</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231103</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.019</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231104</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>13.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.024</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231105</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6949 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     WBANNO  LST_DATE  CRX_VN  LONGITUDE  LATITUDE  T_DAILY_MAX  T_DAILY_MIN  \\\n",
       "0     64758  20041027   1.201     -76.25     42.44          NaN          NaN   \n",
       "1     64758  20041028   1.201     -76.25     42.44         12.7         -0.3   \n",
       "2     64758  20041029   1.201     -76.25     42.44         16.3          2.5   \n",
       "3     64758  20041030   1.201     -76.25     42.44         17.5         10.5   \n",
       "4     64758  20041031   1.201     -76.25     42.44         17.0          9.1   \n",
       "..      ...       ...     ...        ...       ...          ...          ...   \n",
       "304   64758  20231101   2.622     -76.25     42.44          3.5         -2.2   \n",
       "305   64758  20231102   2.622     -76.25     42.44          6.1         -3.3   \n",
       "306   64758  20231103   2.622     -76.25     42.44         12.9          1.4   \n",
       "307   64758  20231104   2.622     -76.25     42.44         13.4          5.7   \n",
       "308   64758  20231105   2.622     -76.25     42.44          NaN          NaN   \n",
       "\n",
       "     T_DAILY_MEAN  T_DAILY_AVG  P_DAILY_CALC  ...  SOIL_MOISTURE_5_DAILY  \\\n",
       "0             NaN          NaN           NaN  ...                    NaN   \n",
       "1             6.2          5.0           0.0  ...                    NaN   \n",
       "2             9.4          9.7           0.0  ...                    NaN   \n",
       "3            14.0         14.5           1.8  ...                    NaN   \n",
       "4            13.1         12.6           0.0  ...                    NaN   \n",
       "..            ...          ...           ...  ...                    ...   \n",
       "304           0.6          0.2           3.0  ...                  0.352   \n",
       "305           1.4          1.0           0.0  ...                  0.352   \n",
       "306           7.1          7.4           0.0  ...                  0.345   \n",
       "307           9.6          9.5           0.0  ...                  0.338   \n",
       "308           NaN          NaN           NaN  ...                    NaN   \n",
       "\n",
       "    SOIL_MOISTURE_10_DAILY  SOIL_MOISTURE_20_DAILY  SOIL_MOISTURE_50_DAILY  \\\n",
       "0                      NaN                     NaN                     NaN   \n",
       "1                      NaN                     NaN                     NaN   \n",
       "2                      NaN                     NaN                     NaN   \n",
       "3                      NaN                     NaN                     NaN   \n",
       "4                      NaN                     NaN                     NaN   \n",
       "..                     ...                     ...                     ...   \n",
       "304                  0.328                   0.329                   0.364   \n",
       "305                  0.323                   0.325                   0.357   \n",
       "306                  0.319                   0.320                   0.327   \n",
       "307                  0.313                   0.312                   0.315   \n",
       "308                    NaN                     NaN                     NaN   \n",
       "\n",
       "     SOIL_MOISTURE_100_DAILY  SOIL_TEMP_5_DAILY  SOIL_TEMP_10_DAILY  \\\n",
       "0                        NaN                NaN                 NaN   \n",
       "1                        NaN                NaN                 NaN   \n",
       "2                        NaN                NaN                 NaN   \n",
       "3                        NaN                NaN                 NaN   \n",
       "4                        NaN                NaN                 NaN   \n",
       "..                       ...                ...                 ...   \n",
       "304                    0.021                7.0                 7.7   \n",
       "305                    0.021                6.4                 6.9   \n",
       "306                    0.019                6.9                 7.0   \n",
       "307                    0.024                8.1                 7.9   \n",
       "308                      NaN                NaN                 NaN   \n",
       "\n",
       "     SOIL_TEMP_20_DAILY  SOIL_TEMP_50_DAILY  SOIL_TEMP_100_DAILY  \n",
       "0                   NaN                 NaN                  NaN  \n",
       "1                   NaN                 NaN                  NaN  \n",
       "2                   NaN                 NaN                  NaN  \n",
       "3                   NaN                 NaN                  NaN  \n",
       "4                   NaN                 NaN                  NaN  \n",
       "..                  ...                 ...                  ...  \n",
       "304                 8.7                10.0                 11.6  \n",
       "305                 7.8                 9.3                 11.3  \n",
       "306                 7.7                 8.9                 10.9  \n",
       "307                 8.3                 8.9                 10.6  \n",
       "308                 NaN                 NaN                  NaN  \n",
       "\n",
       "[6949 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa511986",
   "metadata": {
    "id": "fa511986"
   },
   "outputs": [],
   "source": [
    "Date = pd.to_datetime(df.LST_DATE, format='%Y%m%d', errors='coerce')\n",
    "df['Time'] = Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec34f475",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec34f475",
    "outputId": "b270aad1-8d00-4006-aa4a-6830348c3bda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WBANNO', 'LST_DATE', 'CRX_VN', 'LONGITUDE', 'LATITUDE', 'T_DAILY_MAX',\n",
       "       'T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG', 'P_DAILY_CALC',\n",
       "       'SOLARAD_DAILY', 'SUR_TEMP_DAILY_TYPE', 'SUR_TEMP_DAILY_MAX',\n",
       "       'SUR_TEMP_DAILY_MIN', 'SUR_TEMP_DAILY_AVG', 'RH_DAILY_MAX',\n",
       "       'RH_DAILY_MIN', 'RH_DAILY_AVG', 'SOIL_MOISTURE_5_DAILY',\n",
       "       'SOIL_MOISTURE_10_DAILY', 'SOIL_MOISTURE_20_DAILY',\n",
       "       'SOIL_MOISTURE_50_DAILY', 'SOIL_MOISTURE_100_DAILY',\n",
       "       'SOIL_TEMP_5_DAILY', 'SOIL_TEMP_10_DAILY', 'SOIL_TEMP_20_DAILY',\n",
       "       'SOIL_TEMP_50_DAILY', 'SOIL_TEMP_100_DAILY', 'Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4cc5e3",
   "metadata": {
    "id": "ef4cc5e3"
   },
   "outputs": [],
   "source": [
    "data = df[['T_DAILY_MAX',\n",
    "       'T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG', 'P_DAILY_CALC',\n",
    "       'SOLARAD_DAILY', 'SUR_TEMP_DAILY_MAX',\n",
    "       'SUR_TEMP_DAILY_MIN', 'SUR_TEMP_DAILY_AVG', 'RH_DAILY_MAX',\n",
    "       'RH_DAILY_MIN', 'RH_DAILY_AVG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8058f298",
   "metadata": {
    "id": "8058f298"
   },
   "outputs": [],
   "source": [
    "data.index = df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb188d49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb188d49",
    "outputId": "06c3f53a-c34e-4719-c83f-dc3a2f2b5a06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_DAILY_MAX          -17.90\n",
       "T_DAILY_MIN          -30.90\n",
       "T_DAILY_MEAN         -24.40\n",
       "T_DAILY_AVG          -23.20\n",
       "P_DAILY_CALC           0.00\n",
       "SOLARAD_DAILY          0.06\n",
       "SUR_TEMP_DAILY_MAX   -16.50\n",
       "SUR_TEMP_DAILY_MIN   -36.00\n",
       "SUR_TEMP_DAILY_AVG   -23.60\n",
       "RH_DAILY_MAX          51.50\n",
       "RH_DAILY_MIN          11.90\n",
       "RH_DAILY_AVG          36.40\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for N/A\n",
    "data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b1a43c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21b1a43c",
    "outputId": "ec5cb260-6229-467a-c96c-40c01dacdec9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_DAILY_MAX             76\n",
       "T_DAILY_MIN             76\n",
       "T_DAILY_MEAN            76\n",
       "T_DAILY_AVG             77\n",
       "P_DAILY_CALC            47\n",
       "SOLARAD_DAILY           56\n",
       "SUR_TEMP_DAILY_MAX     438\n",
       "SUR_TEMP_DAILY_MIN     438\n",
       "SUR_TEMP_DAILY_AVG      56\n",
       "RH_DAILY_MAX          2405\n",
       "RH_DAILY_MIN          2405\n",
       "RH_DAILY_AVG          2405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00be0a2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00be0a2f",
    "outputId": "c42f08df-510f-488f-ce80-5559e6e14427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_DAILY_MAX           float64\n",
       "T_DAILY_MIN           float64\n",
       "T_DAILY_MEAN          float64\n",
       "T_DAILY_AVG           float64\n",
       "P_DAILY_CALC          float64\n",
       "SOLARAD_DAILY         float64\n",
       "SUR_TEMP_DAILY_MAX    float64\n",
       "SUR_TEMP_DAILY_MIN    float64\n",
       "SUR_TEMP_DAILY_AVG    float64\n",
       "RH_DAILY_MAX          float64\n",
       "RH_DAILY_MIN          float64\n",
       "RH_DAILY_AVG          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98be58ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98be58ba",
    "outputId": "723b036d-bd78-4de2-896b-0e6d49a3e15d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6949, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d169f2",
   "metadata": {
    "id": "d0d169f2"
   },
   "outputs": [],
   "source": [
    "# forward fill the missing values\n",
    "data.ffill(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1601b98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "f1601b98",
    "outputId": "9d388348-d146-4685-e158-4bcfca9a0671"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_DAILY_MAX</th>\n",
       "      <th>T_DAILY_MIN</th>\n",
       "      <th>T_DAILY_MEAN</th>\n",
       "      <th>T_DAILY_AVG</th>\n",
       "      <th>P_DAILY_CALC</th>\n",
       "      <th>SOLARAD_DAILY</th>\n",
       "      <th>SUR_TEMP_DAILY_MAX</th>\n",
       "      <th>SUR_TEMP_DAILY_MIN</th>\n",
       "      <th>SUR_TEMP_DAILY_AVG</th>\n",
       "      <th>RH_DAILY_MAX</th>\n",
       "      <th>RH_DAILY_MIN</th>\n",
       "      <th>RH_DAILY_AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-10-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>12.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-29</th>\n",
       "      <td>16.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-30</th>\n",
       "      <td>17.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-31</th>\n",
       "      <td>17.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>3.5</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>89.9</td>\n",
       "      <td>69.2</td>\n",
       "      <td>83.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02</th>\n",
       "      <td>6.1</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.21</td>\n",
       "      <td>12.1</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>90.0</td>\n",
       "      <td>53.4</td>\n",
       "      <td>75.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-03</th>\n",
       "      <td>12.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.68</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>63.6</td>\n",
       "      <td>26.1</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-04</th>\n",
       "      <td>13.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.49</td>\n",
       "      <td>16.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-05</th>\n",
       "      <td>13.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.49</td>\n",
       "      <td>16.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6949 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            T_DAILY_MAX  T_DAILY_MIN  T_DAILY_MEAN  T_DAILY_AVG  P_DAILY_CALC  \\\n",
       "Time                                                                            \n",
       "2004-10-27          NaN          NaN           NaN          NaN           NaN   \n",
       "2004-10-28         12.7         -0.3           6.2          5.0           0.0   \n",
       "2004-10-29         16.3          2.5           9.4          9.7           0.0   \n",
       "2004-10-30         17.5         10.5          14.0         14.5           1.8   \n",
       "2004-10-31         17.0          9.1          13.1         12.6           0.0   \n",
       "...                 ...          ...           ...          ...           ...   \n",
       "2023-11-01          3.5         -2.2           0.6          0.2           3.0   \n",
       "2023-11-02          6.1         -3.3           1.4          1.0           0.0   \n",
       "2023-11-03         12.9          1.4           7.1          7.4           0.0   \n",
       "2023-11-04         13.4          5.7           9.6          9.5           0.0   \n",
       "2023-11-05         13.4          5.7           9.6          9.5           0.0   \n",
       "\n",
       "            SOLARAD_DAILY  SUR_TEMP_DAILY_MAX  SUR_TEMP_DAILY_MIN  \\\n",
       "Time                                                                \n",
       "2004-10-27            NaN                 NaN                 NaN   \n",
       "2004-10-28          12.67                 NaN                 NaN   \n",
       "2004-10-29           8.99                 NaN                 NaN   \n",
       "2004-10-30           4.14                 NaN                 NaN   \n",
       "2004-10-31           3.42                 NaN                 NaN   \n",
       "...                   ...                 ...                 ...   \n",
       "2023-11-01           5.25                 9.0                -4.6   \n",
       "2023-11-02           6.21                12.1                -5.2   \n",
       "2023-11-03          10.68                13.5                -1.1   \n",
       "2023-11-04           5.49                16.5                 3.5   \n",
       "2023-11-05           5.49                16.5                 3.5   \n",
       "\n",
       "            SUR_TEMP_DAILY_AVG  RH_DAILY_MAX  RH_DAILY_MIN  RH_DAILY_AVG  \n",
       "Time                                                                      \n",
       "2004-10-27                 NaN           NaN           NaN           NaN  \n",
       "2004-10-28                 6.5           NaN           NaN           NaN  \n",
       "2004-10-29                10.2           NaN           NaN           NaN  \n",
       "2004-10-30                13.5           NaN           NaN           NaN  \n",
       "2004-10-31                10.8           NaN           NaN           NaN  \n",
       "...                        ...           ...           ...           ...  \n",
       "2023-11-01                 0.3          89.9          69.2          83.8  \n",
       "2023-11-02                 0.6          90.0          53.4          75.2  \n",
       "2023-11-03                 5.7          63.6          26.1          43.0  \n",
       "2023-11-04                 8.0          78.3          34.7          50.7  \n",
       "2023-11-05                 8.0          78.3          34.7          50.7  \n",
       "\n",
       "[6949 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cbbdc3a",
   "metadata": {
    "id": "5cbbdc3a"
   },
   "outputs": [],
   "source": [
    "# drop NaN at the top\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6ba21c5",
   "metadata": {
    "id": "a6ba21c5"
   },
   "outputs": [],
   "source": [
    "# set target\n",
    "data['target'] = data['T_DAILY_AVG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6a51031",
   "metadata": {
    "id": "a6a51031"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "597b6d4b",
   "metadata": {
    "id": "597b6d4b"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba1ac71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aba1ac71",
    "outputId": "26de5820-8f95-411f-8874-7d7105534dfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3672, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf181b56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf181b56",
    "outputId": "5f06a974-220c-4a0d-809b-8c5eee7b6e53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99ce69f2",
   "metadata": {
    "id": "99ce69f2"
   },
   "outputs": [],
   "source": [
    "# splitting data into sequences\n",
    "def split_sequences(features, target, seq_len, forecast_len):\n",
    "    X,y = list(), list()\n",
    "    for i in range(len(features)):\n",
    "        end_input = i + seq_len\n",
    "        end_predict = end_input + forecast_len\n",
    "        if end_predict > len(features)-1:\n",
    "            break\n",
    "        seq_x, seq_y = features[i:end_input,:], target[end_input:end_predict]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return tf.convert_to_tensor(X, dtype=tf.float64), tf.convert_to_tensor(y, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc7e6b",
   "metadata": {
    "id": "6adc7e6b"
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e46daa1",
   "metadata": {
    "id": "7e46daa1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RNN, LSTMCell, Input, Bidirectional\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape, name = 'BiLSTM-FC'):\n",
    "        super().__init__(name = name)\n",
    "        self.input_layer = Input(shape = input_shape, name = 'input')\n",
    "        self.lstm1 = Bidirectional(LSTM(units=30, activation = 'tanh', input_shape = input_shape, return_sequences=False, name = 'lstm_1'),name = 'bilstm_1')\n",
    "        self.dense1 = Dense(units=output_shape, activation = 'relu', name = 'dense_1')\n",
    "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.lstm1(inputs)\n",
    "        x = self.dense1(x)\n",
    "        #if training:\n",
    "        #  x = self.dropout(x, training=training)\n",
    "        return x\n",
    "\n",
    "    def summary(self):\n",
    "        model = Model(inputs = [self.input_layer], outputs = self.call(self.input_layer), name = self.name)\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28807bc6",
   "metadata": {
    "id": "28807bc6"
   },
   "source": [
    "# Model Training\n",
    "## input length : output length = 16:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03ec4f70",
   "metadata": {
    "id": "03ec4f70"
   },
   "outputs": [],
   "source": [
    "# prepare sequences\n",
    "seq_len = 16\n",
    "forecast_len = 4\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c26eaa20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c26eaa20",
    "outputId": "765c3d35-253d-4890-ce6c-5aa9a098c39a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3652, 16, 12])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "039bed2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "039bed2b",
    "outputId": "d2a3473c-b45d-41d3-9fe5-f87a359c9a72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3652, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f03c179",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f03c179",
    "outputId": "35b7c868-74f1-49f7-90ca-2d1b99363aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM_16-4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 16, 12)]          0         \n",
      "                                                                 \n",
      " bilstm_1 (Bidirectional)    (None, 60)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 244       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,564\n",
      "Trainable params: 10,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM_16-4'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06942327",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06942327",
    "outputId": "327d16b0-0506-4f7e-b2f8-13764fe2a9f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 3s 24ms/step - loss: 0.0350 - mse: 0.0350 - acc: 0.2474 - val_loss: 0.0089 - val_mse: 0.0089 - val_acc: 0.3142\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0089 - mse: 0.0089 - acc: 0.2663 - val_loss: 0.0067 - val_mse: 0.0067 - val_acc: 0.2705\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0080 - mse: 0.0080 - acc: 0.2833 - val_loss: 0.0068 - val_mse: 0.0068 - val_acc: 0.3087\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - mse: 0.0078 - acc: 0.2995 - val_loss: 0.0069 - val_mse: 0.0069 - val_acc: 0.2951\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.3110 - val_loss: 0.0067 - val_mse: 0.0067 - val_acc: 0.3333\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - mse: 0.0076 - acc: 0.3390 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.2923\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0075 - mse: 0.0075 - acc: 0.3354 - val_loss: 0.0070 - val_mse: 0.0070 - val_acc: 0.3743\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mse: 0.0073 - acc: 0.3116 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.3689\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - mse: 0.0074 - acc: 0.3393 - val_loss: 0.0066 - val_mse: 0.0066 - val_acc: 0.3689\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mse: 0.0073 - acc: 0.3542 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.3142\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - mse: 0.0072 - acc: 0.3411 - val_loss: 0.0077 - val_mse: 0.0077 - val_acc: 0.4044\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mse: 0.0073 - acc: 0.3576 - val_loss: 0.0069 - val_mse: 0.0069 - val_acc: 0.3579\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - mse: 0.0078 - acc: 0.3445 - val_loss: 0.0071 - val_mse: 0.0071 - val_acc: 0.3142\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - mse: 0.0072 - acc: 0.3390 - val_loss: 0.0064 - val_mse: 0.0064 - val_acc: 0.3251\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - acc: 0.3755 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.3962\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - acc: 0.3594 - val_loss: 0.0066 - val_mse: 0.0066 - val_acc: 0.3333\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mse: 0.0071 - acc: 0.3548 - val_loss: 0.0064 - val_mse: 0.0064 - val_acc: 0.3306\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - acc: 0.3472 - val_loss: 0.0064 - val_mse: 0.0064 - val_acc: 0.3333\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0070 - mse: 0.0070 - acc: 0.3631 - val_loss: 0.0064 - val_mse: 0.0064 - val_acc: 0.3169\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - acc: 0.3661 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.3251\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - mse: 0.0069 - acc: 0.3688 - val_loss: 0.0064 - val_mse: 0.0064 - val_acc: 0.3634\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - acc: 0.3646 - val_loss: 0.0071 - val_mse: 0.0071 - val_acc: 0.3934\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mse: 0.0071 - acc: 0.3521 - val_loss: 0.0064 - val_mse: 0.0064 - val_acc: 0.3115\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0069 - mse: 0.0069 - acc: 0.3670 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.3333\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mse: 0.0071 - acc: 0.3548 - val_loss: 0.0067 - val_mse: 0.0067 - val_acc: 0.3388\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0070 - mse: 0.0070 - acc: 0.3658 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.3470\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - mse: 0.0069 - acc: 0.3704 - val_loss: 0.0069 - val_mse: 0.0069 - val_acc: 0.3497\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - acc: 0.3704 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.4098\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mse: 0.0071 - acc: 0.3649 - val_loss: 0.0069 - val_mse: 0.0069 - val_acc: 0.3115\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - mse: 0.0069 - acc: 0.3521 - val_loss: 0.0065 - val_mse: 0.0065 - val_acc: 0.3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models_daily_v2/BiLSTM_16-4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models_daily_v2/BiLSTM_16-4\\assets\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n",
    "# traning for > 40 epoch starts to overfit\n",
    "# save trained model\n",
    "model.save('./LSTM/models_daily_v2/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceea1dc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceea1dc7",
    "outputId": "11ab063d-975d-4ee8-8b0c-a449c2f4aaab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd0043ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd0043ef",
    "outputId": "ddef9dbd-73b2-49db-d6a0-81bb36197fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error\n",
      "train set: 0.006660300351272238\n",
      "test set: 0.006566365723436761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258ce9b",
   "metadata": {
    "id": "1258ce9b"
   },
   "source": [
    "## input length : output length = 24:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8be2411e",
   "metadata": {
    "id": "8be2411e"
   },
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default()\n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 24\n",
    "forecast_len = 6\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "787bb430",
   "metadata": {
    "id": "787bb430",
    "outputId": "54bc67c8-56ed-4d5c-e398-f943317bcf3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM_24-6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 24, 12)]          0         \n",
      "                                                                 \n",
      " bilstm_1 (Bidirectional)    (None, 60)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 366       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,686\n",
      "Trainable params: 10,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM_24-6'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2e8f948",
   "metadata": {
    "id": "c2e8f948",
    "outputId": "8ac4a356-bf84-42af-af69-98dade95567f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33/33 [==============================] - 3s 29ms/step - loss: 0.0961 - mse: 0.0961 - acc: 0.1706 - val_loss: 0.0741 - val_mse: 0.0741 - val_acc: 0.1781\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0719 - mse: 0.0719 - acc: 0.1761 - val_loss: 0.0720 - val_mse: 0.0720 - val_acc: 0.1534\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0713 - mse: 0.0713 - acc: 0.1984 - val_loss: 0.0719 - val_mse: 0.0719 - val_acc: 0.1589\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0710 - mse: 0.0710 - acc: 0.2109 - val_loss: 0.0716 - val_mse: 0.0716 - val_acc: 0.2055\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0709 - mse: 0.0709 - acc: 0.2063 - val_loss: 0.0719 - val_mse: 0.0719 - val_acc: 0.2274\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0709 - mse: 0.0709 - acc: 0.2121 - val_loss: 0.0714 - val_mse: 0.0714 - val_acc: 0.1973\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0708 - mse: 0.0708 - acc: 0.2228 - val_loss: 0.0717 - val_mse: 0.0717 - val_acc: 0.2055\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0707 - mse: 0.0707 - acc: 0.2334 - val_loss: 0.0714 - val_mse: 0.0714 - val_acc: 0.2493\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0706 - mse: 0.0706 - acc: 0.2374 - val_loss: 0.0712 - val_mse: 0.0712 - val_acc: 0.2301\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0706 - mse: 0.0706 - acc: 0.2435 - val_loss: 0.0713 - val_mse: 0.0713 - val_acc: 0.1781\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0708 - mse: 0.0708 - acc: 0.2441 - val_loss: 0.0718 - val_mse: 0.0718 - val_acc: 0.2329\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0706 - mse: 0.0706 - acc: 0.2420 - val_loss: 0.0714 - val_mse: 0.0714 - val_acc: 0.2192\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0705 - mse: 0.0705 - acc: 0.2463 - val_loss: 0.0712 - val_mse: 0.0712 - val_acc: 0.2658\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0704 - mse: 0.0704 - acc: 0.2695 - val_loss: 0.0711 - val_mse: 0.0711 - val_acc: 0.2630\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0704 - mse: 0.0704 - acc: 0.2566 - val_loss: 0.0713 - val_mse: 0.0713 - val_acc: 0.3233\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0706 - mse: 0.0706 - acc: 0.2637 - val_loss: 0.0711 - val_mse: 0.0711 - val_acc: 0.2904\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0704 - mse: 0.0704 - acc: 0.2572 - val_loss: 0.0711 - val_mse: 0.0711 - val_acc: 0.2438\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0705 - mse: 0.0705 - acc: 0.2566 - val_loss: 0.0713 - val_mse: 0.0713 - val_acc: 0.2356\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0704 - mse: 0.0704 - acc: 0.2615 - val_loss: 0.0713 - val_mse: 0.0713 - val_acc: 0.2356\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0706 - mse: 0.0706 - acc: 0.2652 - val_loss: 0.0711 - val_mse: 0.0711 - val_acc: 0.2712\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0703 - mse: 0.0703 - acc: 0.2606 - val_loss: 0.0711 - val_mse: 0.0711 - val_acc: 0.2219\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0704 - mse: 0.0704 - acc: 0.2670 - val_loss: 0.0712 - val_mse: 0.0712 - val_acc: 0.2411\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0703 - mse: 0.0703 - acc: 0.2615 - val_loss: 0.0711 - val_mse: 0.0711 - val_acc: 0.2877\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0702 - mse: 0.0702 - acc: 0.2817 - val_loss: 0.0712 - val_mse: 0.0712 - val_acc: 0.2548\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0703 - mse: 0.0703 - acc: 0.2722 - val_loss: 0.0710 - val_mse: 0.0710 - val_acc: 0.2658\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0704 - mse: 0.0704 - acc: 0.2740 - val_loss: 0.0716 - val_mse: 0.0716 - val_acc: 0.2767\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0704 - mse: 0.0704 - acc: 0.2646 - val_loss: 0.0713 - val_mse: 0.0713 - val_acc: 0.2767\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0703 - mse: 0.0703 - acc: 0.2716 - val_loss: 0.0710 - val_mse: 0.0710 - val_acc: 0.2904\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0704 - mse: 0.0704 - acc: 0.2710 - val_loss: 0.0710 - val_mse: 0.0710 - val_acc: 0.2466\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0705 - mse: 0.0705 - acc: 0.2685 - val_loss: 0.0711 - val_mse: 0.0711 - val_acc: 0.2411\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0702 - mse: 0.0702 - acc: 0.2637 - val_loss: 0.0710 - val_mse: 0.0710 - val_acc: 0.2384\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0702 - mse: 0.0702 - acc: 0.2673 - val_loss: 0.0710 - val_mse: 0.0710 - val_acc: 0.2658\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0221 - mse: 0.0221 - acc: 0.2066 - val_loss: 0.0079 - val_mse: 0.0079 - val_acc: 0.1315\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.2359 - val_loss: 0.0072 - val_mse: 0.0072 - val_acc: 0.2548\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0076 - mse: 0.0076 - acc: 0.2621 - val_loss: 0.0072 - val_mse: 0.0072 - val_acc: 0.2521\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0075 - mse: 0.0075 - acc: 0.2627 - val_loss: 0.0072 - val_mse: 0.0072 - val_acc: 0.2411\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0075 - mse: 0.0075 - acc: 0.2710 - val_loss: 0.0070 - val_mse: 0.0070 - val_acc: 0.2438\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0075 - mse: 0.0075 - acc: 0.2716 - val_loss: 0.0070 - val_mse: 0.0070 - val_acc: 0.2822\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0074 - mse: 0.0074 - acc: 0.2704 - val_loss: 0.0070 - val_mse: 0.0070 - val_acc: 0.3096\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0076 - mse: 0.0076 - acc: 0.2731 - val_loss: 0.0069 - val_mse: 0.0069 - val_acc: 0.2630\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0073 - mse: 0.0073 - acc: 0.2667 - val_loss: 0.0070 - val_mse: 0.0070 - val_acc: 0.2575\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0074 - mse: 0.0074 - acc: 0.2759 - val_loss: 0.0069 - val_mse: 0.0069 - val_acc: 0.2822\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0075 - mse: 0.0075 - acc: 0.2710 - val_loss: 0.0069 - val_mse: 0.0069 - val_acc: 0.2658\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0075 - mse: 0.0075 - acc: 0.2624 - val_loss: 0.0070 - val_mse: 0.0070 - val_acc: 0.2082\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0074 - mse: 0.0074 - acc: 0.2585 - val_loss: 0.0073 - val_mse: 0.0073 - val_acc: 0.2411\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0074 - mse: 0.0074 - acc: 0.2685 - val_loss: 0.0070 - val_mse: 0.0070 - val_acc: 0.2986\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0073 - mse: 0.0073 - acc: 0.2673 - val_loss: 0.0071 - val_mse: 0.0071 - val_acc: 0.2740\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0073 - mse: 0.0073 - acc: 0.2649 - val_loss: 0.0070 - val_mse: 0.0070 - val_acc: 0.2438\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0075 - mse: 0.0075 - acc: 0.2542 - val_loss: 0.0074 - val_mse: 0.0074 - val_acc: 0.2795\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0073 - mse: 0.0073 - acc: 0.2746 - val_loss: 0.0068 - val_mse: 0.0068 - val_acc: 0.2521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c04f73580>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=100,\n",
    "          epochs=50,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "520fc1a0",
   "metadata": {
    "id": "520fc1a0",
    "outputId": "8f3c74b0-4fe1-40a9-fd1f-b85fac9efb6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models_daily_v2/BiLSTM_24-6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models_daily_v2/BiLSTM_24-6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 2ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "mean_squared_error\n",
      "train set: 0.007152441633439636\n",
      "test set: 0.006911209424476951\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# save trained model\n",
    "model.save('./LSTM/models_daily_v2/' + model_name)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dbd001",
   "metadata": {
    "id": "82dbd001"
   },
   "source": [
    "## input length : output length = 32:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86bc5076",
   "metadata": {
    "id": "86bc5076"
   },
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default()\n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 32\n",
    "forecast_len = 8\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab4164d4",
   "metadata": {
    "id": "ab4164d4",
    "outputId": "d7523ef9-bb0a-4785-fb62-58000a5af611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM_32-8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 32, 12)]          0         \n",
      "                                                                 \n",
      " bilstm_1 (Bidirectional)    (None, 60)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 488       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,808\n",
      "Trainable params: 10,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM_32-8'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b571424",
   "metadata": {
    "id": "0b571424",
    "outputId": "7f3720b5-35d9-46f8-a945-642272faf6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33/33 [==============================] - 3s 34ms/step - loss: 0.0778 - mse: 0.0778 - acc: 0.1258 - val_loss: 0.0582 - val_mse: 0.0582 - val_acc: 0.1099\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0569 - mse: 0.0569 - acc: 0.1340 - val_loss: 0.0562 - val_mse: 0.0562 - val_acc: 0.1566\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0558 - mse: 0.0558 - acc: 0.1405 - val_loss: 0.0558 - val_mse: 0.0558 - val_acc: 0.1429\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0560 - mse: 0.0560 - acc: 0.1509 - val_loss: 0.0559 - val_mse: 0.0559 - val_acc: 0.1621\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0557 - mse: 0.0557 - acc: 0.1671 - val_loss: 0.0557 - val_mse: 0.0557 - val_acc: 0.1703\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0554 - mse: 0.0554 - acc: 0.1784 - val_loss: 0.0560 - val_mse: 0.0560 - val_acc: 0.1291\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0554 - mse: 0.0554 - acc: 0.1790 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.2170\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0554 - mse: 0.0554 - acc: 0.1894 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.1621\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0554 - mse: 0.0554 - acc: 0.1912 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.1896\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0552 - mse: 0.0552 - acc: 0.1965 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.2033\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0553 - mse: 0.0553 - acc: 0.1949 - val_loss: 0.0571 - val_mse: 0.0571 - val_acc: 0.2033\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0557 - mse: 0.0557 - acc: 0.1851 - val_loss: 0.0557 - val_mse: 0.0557 - val_acc: 0.1841\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0554 - mse: 0.0554 - acc: 0.1934 - val_loss: 0.0560 - val_mse: 0.0560 - val_acc: 0.2115\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0554 - mse: 0.0554 - acc: 0.1986 - val_loss: 0.0555 - val_mse: 0.0555 - val_acc: 0.2005\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0552 - mse: 0.0552 - acc: 0.2026 - val_loss: 0.0555 - val_mse: 0.0555 - val_acc: 0.2060\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0551 - mse: 0.0551 - acc: 0.2041 - val_loss: 0.0563 - val_mse: 0.0563 - val_acc: 0.2170\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0556 - mse: 0.0556 - acc: 0.1986 - val_loss: 0.0557 - val_mse: 0.0557 - val_acc: 0.1813\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0552 - mse: 0.0552 - acc: 0.1965 - val_loss: 0.0558 - val_mse: 0.0558 - val_acc: 0.1951\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0552 - mse: 0.0552 - acc: 0.2010 - val_loss: 0.0555 - val_mse: 0.0555 - val_acc: 0.1923\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0552 - mse: 0.0552 - acc: 0.1943 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.1758\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0550 - mse: 0.0550 - acc: 0.1885 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.2253\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0550 - mse: 0.0550 - acc: 0.1940 - val_loss: 0.0557 - val_mse: 0.0557 - val_acc: 0.2005\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0551 - mse: 0.0551 - acc: 0.2121 - val_loss: 0.0555 - val_mse: 0.0555 - val_acc: 0.1896\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0550 - mse: 0.0550 - acc: 0.2059 - val_loss: 0.0555 - val_mse: 0.0555 - val_acc: 0.1703\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0550 - mse: 0.0550 - acc: 0.2142 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.1923\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0551 - mse: 0.0551 - acc: 0.2001 - val_loss: 0.0558 - val_mse: 0.0558 - val_acc: 0.2198\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0552 - mse: 0.0552 - acc: 0.2017 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.1731\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0549 - mse: 0.0549 - acc: 0.2072 - val_loss: 0.0556 - val_mse: 0.0556 - val_acc: 0.1868\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0551 - mse: 0.0551 - acc: 0.2032 - val_loss: 0.0555 - val_mse: 0.0555 - val_acc: 0.2033\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0549 - mse: 0.0549 - acc: 0.2041 - val_loss: 0.0555 - val_mse: 0.0555 - val_acc: 0.1978\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0549 - mse: 0.0549 - acc: 0.2111 - val_loss: 0.0555 - val_mse: 0.0555 - val_acc: 0.1896\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0549 - mse: 0.0549 - acc: 0.2142 - val_loss: 0.0554 - val_mse: 0.0554 - val_acc: 0.1978\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0548 - mse: 0.0548 - acc: 0.2013 - val_loss: 0.0554 - val_mse: 0.0554 - val_acc: 0.1951\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0549 - mse: 0.0549 - acc: 0.2075 - val_loss: 0.0554 - val_mse: 0.0554 - val_acc: 0.1841\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0297 - mse: 0.0297 - acc: 0.1747 - val_loss: 0.0079 - val_mse: 0.0079 - val_acc: 0.1896\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0083 - mse: 0.0083 - acc: 0.1784 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1703\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0080 - mse: 0.0080 - acc: 0.2007 - val_loss: 0.0077 - val_mse: 0.0077 - val_acc: 0.2088\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0081 - mse: 0.0081 - acc: 0.2010 - val_loss: 0.0075 - val_mse: 0.0075 - val_acc: 0.2198\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0081 - mse: 0.0081 - acc: 0.2136 - val_loss: 0.0080 - val_mse: 0.0080 - val_acc: 0.2225\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0078 - mse: 0.0078 - acc: 0.2166 - val_loss: 0.0089 - val_mse: 0.0089 - val_acc: 0.1951\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0080 - mse: 0.0080 - acc: 0.2081 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.2280\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.2166 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.2088\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.2234 - val_loss: 0.0073 - val_mse: 0.0073 - val_acc: 0.1923\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.2206 - val_loss: 0.0075 - val_mse: 0.0075 - val_acc: 0.1786\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.2154 - val_loss: 0.0074 - val_mse: 0.0074 - val_acc: 0.2005\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0080 - mse: 0.0080 - acc: 0.2072 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1841\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0078 - mse: 0.0078 - acc: 0.2087 - val_loss: 0.0075 - val_mse: 0.0075 - val_acc: 0.2115\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.2243 - val_loss: 0.0074 - val_mse: 0.0074 - val_acc: 0.2308\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.2215 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1978\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0077 - mse: 0.0077 - acc: 0.2081 - val_loss: 0.0075 - val_mse: 0.0075 - val_acc: 0.2005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c0c8f2620>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=100,\n",
    "          epochs=50,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed47bbbb",
   "metadata": {
    "id": "ed47bbbb",
    "outputId": "7c5c3683-2276-48de-f836-5addae59c1b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models_daily_v2/BiLSTM_32-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models_daily_v2/BiLSTM_32-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 2ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "mean_squared_error\n",
      "train set: 0.00758172590045909\n",
      "test set: 0.0070981972944135965\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models_daily_v2/' + model_name)\n",
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e0a20",
   "metadata": {
    "id": "147e0a20"
   },
   "source": [
    "## input length : output length = 40:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c9521fc",
   "metadata": {
    "id": "0c9521fc"
   },
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default()\n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 40\n",
    "forecast_len = 10\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2091b9f3",
   "metadata": {
    "id": "2091b9f3",
    "outputId": "4ce3fc97-fc9a-42c0-9684-6763e9693c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM_40-10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 40, 12)]          0         \n",
      "                                                                 \n",
      " bilstm_1 (Bidirectional)    (None, 60)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                610       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,930\n",
      "Trainable params: 10,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM_40-10'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2de6ddb4",
   "metadata": {
    "id": "2de6ddb4",
    "outputId": "cac550bf-dc35-40d3-8f6d-5aba0b2b63a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 4s 37ms/step - loss: 0.0497 - mse: 0.0497 - acc: 0.0979 - val_loss: 0.0086 - val_mse: 0.0086 - val_acc: 0.1570\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0094 - mse: 0.0094 - acc: 0.1120 - val_loss: 0.0082 - val_mse: 0.0082 - val_acc: 0.1433\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0088 - mse: 0.0088 - acc: 0.1237 - val_loss: 0.0080 - val_mse: 0.0080 - val_acc: 0.1515\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0087 - mse: 0.0087 - acc: 0.1350 - val_loss: 0.0082 - val_mse: 0.0082 - val_acc: 0.1102\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0085 - mse: 0.0085 - acc: 0.1402 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1708\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0087 - mse: 0.0087 - acc: 0.1448 - val_loss: 0.0077 - val_mse: 0.0077 - val_acc: 0.1653\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0083 - mse: 0.0083 - acc: 0.1442 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1543\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0084 - mse: 0.0084 - acc: 0.1479 - val_loss: 0.0075 - val_mse: 0.0075 - val_acc: 0.1570\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0087 - mse: 0.0087 - acc: 0.1531 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1295\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0086 - mse: 0.0086 - acc: 0.1513 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1185\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0084 - mse: 0.0084 - acc: 0.1510 - val_loss: 0.0074 - val_mse: 0.0074 - val_acc: 0.1763\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0084 - mse: 0.0084 - acc: 0.1546 - val_loss: 0.0081 - val_mse: 0.0081 - val_acc: 0.1322\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0084 - mse: 0.0084 - acc: 0.1540 - val_loss: 0.0075 - val_mse: 0.0075 - val_acc: 0.1598\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0081 - mse: 0.0081 - acc: 0.1700 - val_loss: 0.0077 - val_mse: 0.0077 - val_acc: 0.1736\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0081 - mse: 0.0081 - acc: 0.1614 - val_loss: 0.0082 - val_mse: 0.0082 - val_acc: 0.1625\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0082 - mse: 0.0082 - acc: 0.1546 - val_loss: 0.0074 - val_mse: 0.0074 - val_acc: 0.1515\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0082 - mse: 0.0082 - acc: 0.1681 - val_loss: 0.0087 - val_mse: 0.0087 - val_acc: 0.1433\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0085 - mse: 0.0085 - acc: 0.1626 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1350\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0080 - mse: 0.0080 - acc: 0.1632 - val_loss: 0.0074 - val_mse: 0.0074 - val_acc: 0.1983\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0081 - mse: 0.0081 - acc: 0.1685 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1928\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0080 - mse: 0.0080 - acc: 0.1669 - val_loss: 0.0078 - val_mse: 0.0078 - val_acc: 0.1873\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0080 - mse: 0.0080 - acc: 0.1623 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1680\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0081 - mse: 0.0081 - acc: 0.1632 - val_loss: 0.0078 - val_mse: 0.0078 - val_acc: 0.1488\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0079 - mse: 0.0079 - acc: 0.1712 - val_loss: 0.0078 - val_mse: 0.0078 - val_acc: 0.1846\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0079 - mse: 0.0079 - acc: 0.1740 - val_loss: 0.0075 - val_mse: 0.0075 - val_acc: 0.1295\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0083 - mse: 0.0083 - acc: 0.1770 - val_loss: 0.0082 - val_mse: 0.0082 - val_acc: 0.1570\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0079 - mse: 0.0079 - acc: 0.1758 - val_loss: 0.0078 - val_mse: 0.0078 - val_acc: 0.1488\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0079 - mse: 0.0079 - acc: 0.1789 - val_loss: 0.0074 - val_mse: 0.0074 - val_acc: 0.1791\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0078 - mse: 0.0078 - acc: 0.1752 - val_loss: 0.0074 - val_mse: 0.0074 - val_acc: 0.1680\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0079 - mse: 0.0079 - acc: 0.1774 - val_loss: 0.0076 - val_mse: 0.0076 - val_acc: 0.1708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c1b3ca500>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "881a1c18",
   "metadata": {
    "id": "881a1c18",
    "outputId": "2e999896-72ae-4c03-adec-032940ce0661"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_22_layer_call_fn, lstm_cell_22_layer_call_and_return_conditional_losses, lstm_cell_23_layer_call_fn, lstm_cell_23_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models_daily_v2/BiLSTM_40-10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models_daily_v2/BiLSTM_40-10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 2ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "mean_squared_error\n",
      "train set: 0.007782176415058797\n",
      "test set: 0.007640175914499972\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models_daily_v2/' + model_name)\n",
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835da065",
   "metadata": {
    "id": "835da065"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
