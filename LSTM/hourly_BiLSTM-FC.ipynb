{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3788ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ec7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:From C:\\Users\\Beebe\\AppData\\Local\\Temp\\ipykernel_13960\\4004085722.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "\n",
      "CUDA GPU: True\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB=True\n",
    "except:\n",
    "    IN_COLAB=False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"We're running Colab\")\n",
    "else:\n",
    "    print(tf.config.list_physical_devices())\n",
    "    print('\\nCUDA GPU: ' + str(tf.test.is_gpu_available(cuda_only=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ebbfa",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825068e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "df = pd.read_csv('./hourly02-ithaca/hourly02-NY_Ithaca_13_E.csv', header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1182c379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WBANNO</th>\n",
       "      <th>UTC_DATE</th>\n",
       "      <th>UTC_TIME</th>\n",
       "      <th>LST_DATE</th>\n",
       "      <th>LST_TIME</th>\n",
       "      <th>CRX_VN</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>T_CALC</th>\n",
       "      <th>T_HR_AVG</th>\n",
       "      <th>...</th>\n",
       "      <th>SOIL_MOISTURE_5</th>\n",
       "      <th>SOIL_MOISTURE_10</th>\n",
       "      <th>SOIL_MOISTURE_20</th>\n",
       "      <th>SOIL_MOISTURE_50</th>\n",
       "      <th>SOIL_MOISTURE_100</th>\n",
       "      <th>SOIL_TEMP_5</th>\n",
       "      <th>SOIL_TEMP_10</th>\n",
       "      <th>SOIL_TEMP_20</th>\n",
       "      <th>SOIL_TEMP_50</th>\n",
       "      <th>SOIL_TEMP_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041027</td>\n",
       "      <td>2200</td>\n",
       "      <td>20041027</td>\n",
       "      <td>1700</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041027</td>\n",
       "      <td>2300</td>\n",
       "      <td>20041027</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041028</td>\n",
       "      <td>0</td>\n",
       "      <td>20041027</td>\n",
       "      <td>1900</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041028</td>\n",
       "      <td>100</td>\n",
       "      <td>20041027</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64758</td>\n",
       "      <td>20041028</td>\n",
       "      <td>200</td>\n",
       "      <td>20041027</td>\n",
       "      <td>2100</td>\n",
       "      <td>1.201</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7415</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231106</td>\n",
       "      <td>0</td>\n",
       "      <td>20231105</td>\n",
       "      <td>1900</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.023</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7416</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231106</td>\n",
       "      <td>100</td>\n",
       "      <td>20231105</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.021</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7417</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231106</td>\n",
       "      <td>200</td>\n",
       "      <td>20231105</td>\n",
       "      <td>2100</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.022</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7418</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231106</td>\n",
       "      <td>300</td>\n",
       "      <td>20231105</td>\n",
       "      <td>2200</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.022</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7419</th>\n",
       "      <td>64758</td>\n",
       "      <td>20231106</td>\n",
       "      <td>400</td>\n",
       "      <td>20231105</td>\n",
       "      <td>2300</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-76.25</td>\n",
       "      <td>42.44</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.022</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166759 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      WBANNO  UTC_DATE  UTC_TIME  LST_DATE  LST_TIME  CRX_VN  LONGITUDE  \\\n",
       "0      64758  20041027      2200  20041027      1700   1.201     -76.25   \n",
       "1      64758  20041027      2300  20041027      1800   1.201     -76.25   \n",
       "2      64758  20041028         0  20041027      1900   1.201     -76.25   \n",
       "3      64758  20041028       100  20041027      2000   1.201     -76.25   \n",
       "4      64758  20041028       200  20041027      2100   1.201     -76.25   \n",
       "...      ...       ...       ...       ...       ...     ...        ...   \n",
       "7415   64758  20231106         0  20231105      1900   2.622     -76.25   \n",
       "7416   64758  20231106       100  20231105      2000   2.622     -76.25   \n",
       "7417   64758  20231106       200  20231105      2100   2.622     -76.25   \n",
       "7418   64758  20231106       300  20231105      2200   2.622     -76.25   \n",
       "7419   64758  20231106       400  20231105      2300   2.622     -76.25   \n",
       "\n",
       "      LATITUDE  T_CALC  T_HR_AVG  ...  SOIL_MOISTURE_5  SOIL_MOISTURE_10  \\\n",
       "0        42.44     NaN       NaN  ...              NaN               NaN   \n",
       "1        42.44     NaN       NaN  ...              NaN               NaN   \n",
       "2        42.44     7.8       7.6  ...              NaN               NaN   \n",
       "3        42.44     6.5       7.0  ...              NaN               NaN   \n",
       "4        42.44     5.4       6.2  ...              NaN               NaN   \n",
       "...        ...     ...       ...  ...              ...               ...   \n",
       "7415     42.44     1.1       1.3  ...            0.336             0.308   \n",
       "7416     42.44    -0.1       0.0  ...            0.336             0.309   \n",
       "7417     42.44    -0.5      -0.4  ...            0.336             0.309   \n",
       "7418     42.44    -1.4      -1.3  ...            0.336             0.309   \n",
       "7419     42.44    -1.9      -1.6  ...            0.336             0.309   \n",
       "\n",
       "      SOIL_MOISTURE_20  SOIL_MOISTURE_50  SOIL_MOISTURE_100  SOIL_TEMP_5  \\\n",
       "0                  NaN               NaN                NaN          NaN   \n",
       "1                  NaN               NaN                NaN          NaN   \n",
       "2                  NaN               NaN                NaN          NaN   \n",
       "3                  NaN               NaN                NaN          NaN   \n",
       "4                  NaN               NaN                NaN          NaN   \n",
       "...                ...               ...                ...          ...   \n",
       "7415             0.307             0.309              0.023          7.6   \n",
       "7416             0.307             0.309              0.021          7.3   \n",
       "7417             0.308             0.309              0.022          7.0   \n",
       "7418             0.308             0.309              0.022          6.8   \n",
       "7419             0.307             0.310              0.022          6.6   \n",
       "\n",
       "      SOIL_TEMP_10  SOIL_TEMP_20  SOIL_TEMP_50 SOIL_TEMP_100  \n",
       "0              NaN           NaN           NaN           NaN  \n",
       "1              NaN           NaN           NaN           NaN  \n",
       "2              NaN           NaN           NaN           NaN  \n",
       "3              NaN           NaN           NaN           NaN  \n",
       "4              NaN           NaN           NaN           NaN  \n",
       "...            ...           ...           ...           ...  \n",
       "7415           8.2           8.8           9.1          10.4  \n",
       "7416           8.0           8.8           9.1          10.4  \n",
       "7417           7.9           8.7           9.2          10.4  \n",
       "7418           7.7           8.6           9.1          10.6  \n",
       "7419           7.6           8.4           9.2          10.4  \n",
       "\n",
       "[166759 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa511986",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = pd.to_datetime(df.UTC_DATE, format='%Y%m%d', errors='coerce')\n",
    "+ pd.to_timedelta(df.UTC_TIME//100, unit = 'hours')\n",
    "df['Time'] = Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec34f475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WBANNO', 'UTC_DATE', 'UTC_TIME', 'LST_DATE', 'LST_TIME', 'CRX_VN',\n",
       "       'LONGITUDE', 'LATITUDE', 'T_CALC', 'T_HR_AVG', 'T_MAX', 'T_MIN',\n",
       "       'P_CALC', 'SOLARAD', 'SOLARAD_FLAG', 'SOLARAD_MAX', 'SOLARAD_MAX_FLAG',\n",
       "       'SOLARAD_MIN', 'SOLARAD_MIN_FLAG', 'SUR_TEMP_TYPE', 'SUR_TEMP',\n",
       "       'SUR_TEMP_FLAG', 'SUR_TEMP_MAX', 'SUR_TEMP_MAX_FLAG', 'SUR_TEMP_MIN',\n",
       "       'SUR_TEMP_MIN_FLAG', 'RH_HR_AVG', 'RH_HR_AVG_FLAG', 'SOIL_MOISTURE_5',\n",
       "       'SOIL_MOISTURE_10', 'SOIL_MOISTURE_20', 'SOIL_MOISTURE_50',\n",
       "       'SOIL_MOISTURE_100', 'SOIL_TEMP_5', 'SOIL_TEMP_10', 'SOIL_TEMP_20',\n",
       "       'SOIL_TEMP_50', 'SOIL_TEMP_100', 'Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4cc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['T_CALC', 'T_HR_AVG', 'T_MAX', 'T_MIN',\n",
    "       'P_CALC', 'SOLARAD', 'SOLARAD_MAX',\n",
    "       'SOLARAD_MIN', 'SUR_TEMP',\n",
    "           'SUR_TEMP_MAX', 'SUR_TEMP_MIN', 'RH_HR_AVG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8058f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb188d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_CALC         -30.8\n",
       "T_HR_AVG       -29.3\n",
       "T_MAX          -28.4\n",
       "T_MIN          -30.9\n",
       "P_CALC           0.0\n",
       "SOLARAD          0.0\n",
       "SOLARAD_MAX      0.0\n",
       "SOLARAD_MIN      0.0\n",
       "SUR_TEMP       -35.8\n",
       "SUR_TEMP_MAX   -61.0\n",
       "SUR_TEMP_MIN   -36.0\n",
       "RH_HR_AVG        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for N/A\n",
    "data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba2a471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_CALC</th>\n",
       "      <th>T_HR_AVG</th>\n",
       "      <th>T_MAX</th>\n",
       "      <th>T_MIN</th>\n",
       "      <th>P_CALC</th>\n",
       "      <th>SOLARAD</th>\n",
       "      <th>SOLARAD_MAX</th>\n",
       "      <th>SOLARAD_MIN</th>\n",
       "      <th>SUR_TEMP</th>\n",
       "      <th>SUR_TEMP_MAX</th>\n",
       "      <th>SUR_TEMP_MIN</th>\n",
       "      <th>RH_HR_AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-10-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>7.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>5.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166759 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            T_CALC  T_HR_AVG  T_MAX  T_MIN  P_CALC  SOLARAD  SOLARAD_MAX  \\\n",
       "Time                                                                       \n",
       "2004-10-27     NaN       NaN    NaN    NaN     NaN     27.0          NaN   \n",
       "2004-10-27     NaN       NaN    NaN    NaN     NaN      0.0          NaN   \n",
       "2004-10-28     7.8       7.6    8.0    7.3     0.0      0.0          NaN   \n",
       "2004-10-28     6.5       7.0    7.8    6.5     0.0      0.0          NaN   \n",
       "2004-10-28     5.4       6.2    6.5    5.4     0.0      0.0          NaN   \n",
       "...            ...       ...    ...    ...     ...      ...          ...   \n",
       "2023-11-06     1.1       1.3    2.1    0.3     0.0      0.0          0.0   \n",
       "2023-11-06    -0.1       0.0    1.0   -1.1     0.0      0.0          0.0   \n",
       "2023-11-06    -0.5      -0.4    0.1   -0.7     0.0      0.0          0.0   \n",
       "2023-11-06    -1.4      -1.3   -0.5   -1.7     0.0      0.0          0.0   \n",
       "2023-11-06    -1.9      -1.6   -1.4   -2.2     0.0      0.0          0.0   \n",
       "\n",
       "            SOLARAD_MIN  SUR_TEMP  SUR_TEMP_MAX  SUR_TEMP_MIN  RH_HR_AVG  \n",
       "Time                                                                      \n",
       "2004-10-27          NaN       8.8           NaN           NaN        0.0  \n",
       "2004-10-27          NaN       6.7           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       6.1           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       5.6           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       5.0           NaN           NaN        0.0  \n",
       "...                 ...       ...           ...           ...        ...  \n",
       "2023-11-06          0.0      -1.6          -0.9          -2.0       76.0  \n",
       "2023-11-06          0.0      -2.3          -1.9          -2.8       80.0  \n",
       "2023-11-06          0.0      -3.1          -2.8          -3.3       83.0  \n",
       "2023-11-06          0.0      -3.2          -2.8          -3.5       85.0  \n",
       "2023-11-06          0.0      -3.5          -3.3          -3.8       87.0  \n",
       "\n",
       "[166759 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b1a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_CALC           1384\n",
       "T_HR_AVG         1446\n",
       "T_MAX            1385\n",
       "T_MIN            1389\n",
       "P_CALC            832\n",
       "SOLARAD           570\n",
       "SOLARAD_MAX      9757\n",
       "SOLARAD_MIN      9757\n",
       "SUR_TEMP          724\n",
       "SUR_TEMP_MAX     9911\n",
       "SUR_TEMP_MIN     9911\n",
       "RH_HR_AVG       48248\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00be0a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_CALC          float64\n",
       "T_HR_AVG        float64\n",
       "T_MAX           float64\n",
       "T_MIN           float64\n",
       "P_CALC          float64\n",
       "SOLARAD         float64\n",
       "SOLARAD_MAX     float64\n",
       "SOLARAD_MIN     float64\n",
       "SUR_TEMP        float64\n",
       "SUR_TEMP_MAX    float64\n",
       "SUR_TEMP_MIN    float64\n",
       "RH_HR_AVG       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98be58ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166759, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d169f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill the missing values  \n",
    "data.ffill(axis = 0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1601b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_CALC</th>\n",
       "      <th>T_HR_AVG</th>\n",
       "      <th>T_MAX</th>\n",
       "      <th>T_MIN</th>\n",
       "      <th>P_CALC</th>\n",
       "      <th>SOLARAD</th>\n",
       "      <th>SOLARAD_MAX</th>\n",
       "      <th>SOLARAD_MIN</th>\n",
       "      <th>SUR_TEMP</th>\n",
       "      <th>SUR_TEMP_MAX</th>\n",
       "      <th>SUR_TEMP_MIN</th>\n",
       "      <th>RH_HR_AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-10-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>7.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-28</th>\n",
       "      <td>5.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166759 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            T_CALC  T_HR_AVG  T_MAX  T_MIN  P_CALC  SOLARAD  SOLARAD_MAX  \\\n",
       "Time                                                                       \n",
       "2004-10-27     NaN       NaN    NaN    NaN     NaN     27.0          NaN   \n",
       "2004-10-27     NaN       NaN    NaN    NaN     NaN      0.0          NaN   \n",
       "2004-10-28     7.8       7.6    8.0    7.3     0.0      0.0          NaN   \n",
       "2004-10-28     6.5       7.0    7.8    6.5     0.0      0.0          NaN   \n",
       "2004-10-28     5.4       6.2    6.5    5.4     0.0      0.0          NaN   \n",
       "...            ...       ...    ...    ...     ...      ...          ...   \n",
       "2023-11-06     1.1       1.3    2.1    0.3     0.0      0.0          0.0   \n",
       "2023-11-06    -0.1       0.0    1.0   -1.1     0.0      0.0          0.0   \n",
       "2023-11-06    -0.5      -0.4    0.1   -0.7     0.0      0.0          0.0   \n",
       "2023-11-06    -1.4      -1.3   -0.5   -1.7     0.0      0.0          0.0   \n",
       "2023-11-06    -1.9      -1.6   -1.4   -2.2     0.0      0.0          0.0   \n",
       "\n",
       "            SOLARAD_MIN  SUR_TEMP  SUR_TEMP_MAX  SUR_TEMP_MIN  RH_HR_AVG  \n",
       "Time                                                                      \n",
       "2004-10-27          NaN       8.8           NaN           NaN        0.0  \n",
       "2004-10-27          NaN       6.7           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       6.1           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       5.6           NaN           NaN        0.0  \n",
       "2004-10-28          NaN       5.0           NaN           NaN        0.0  \n",
       "...                 ...       ...           ...           ...        ...  \n",
       "2023-11-06          0.0      -1.6          -0.9          -2.0       76.0  \n",
       "2023-11-06          0.0      -2.3          -1.9          -2.8       80.0  \n",
       "2023-11-06          0.0      -3.1          -2.8          -3.3       83.0  \n",
       "2023-11-06          0.0      -3.2          -2.8          -3.5       85.0  \n",
       "2023-11-06          0.0      -3.5          -3.3          -3.8       87.0  \n",
       "\n",
       "[166759 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cbbdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN at the top\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ba21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target\n",
    "data['target'] = data['T_HR_AVG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a14eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "scaled_data = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6a51031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(scaled_data, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aba1ac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126057, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf181b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31515, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ce69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into sequences\n",
    "def split_sequences(features, target, seq_len, forecast_len):\n",
    "    X,y = list(), list()\n",
    "    for i in range(len(features)):\n",
    "        end_input = i + seq_len\n",
    "        end_predict = end_input + forecast_len\n",
    "        if end_predict > len(features)-1:\n",
    "            break\n",
    "        seq_x, seq_y = features[i:end_input,:], target[end_input:end_predict]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return tf.convert_to_tensor(X, dtype=tf.float64), tf.convert_to_tensor(y, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc7e6b",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e46daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RNN, LSTMCell, Input, Bidirectional\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape, name = 'BiLSTM-FC'):\n",
    "        super().__init__(name = name)\n",
    "        self.input_layer = Input(shape = input_shape, name = 'input')\n",
    "        self.lstm1 = Bidirectional(LSTM(units=30, activation = 'tanh', input_shape = input_shape, return_sequences=False, name = 'lstm_1'), name = 'bilstm_1')\n",
    "        self.dense1 = Dense(units=20, activation = 'relu', name = 'dense_1')\n",
    "        self.dense2 = Dense(units=10, activation = 'relu', name = 'dense_2')\n",
    "        self.dense3 = Dense(units = output_shape, activation = None, name = 'dense_3')\n",
    "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.lstm1(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        #if training:\n",
    "        #  x = self.dropout(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def summary(self):\n",
    "        model = Model(inputs = [self.input_layer], outputs = self.call(self.input_layer), name = self.name)\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28807bc6",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "## input length : output length = 16:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03ec4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequences\n",
    "seq_len = 16\n",
    "forecast_len = 4\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c26eaa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([126037, 16, 12])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "039bed2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([126037, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f03c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM-FC_16-4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 16, 12)]          0         \n",
      "_________________________________________________________________\n",
      "bilstm_1 (Bidirectional)     (None, 60)                10320     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 11,794\n",
      "Trainable params: 11,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM-FC_16-4'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06942327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 20s 12ms/step - loss: 0.0023 - mse: 0.0023 - acc: 0.3966 - val_loss: 7.3599e-04 - val_mse: 7.3599e-04 - val_acc: 0.5280\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 7.1901e-04 - mse: 7.1901e-04 - acc: 0.6018 - val_loss: 5.9521e-04 - val_mse: 5.9521e-04 - val_acc: 0.6135\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 6.2301e-04 - mse: 6.2301e-04 - acc: 0.6308 - val_loss: 5.2964e-04 - val_mse: 5.2964e-04 - val_acc: 0.6131\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 5.9302e-04 - mse: 5.9302e-04 - acc: 0.6383 - val_loss: 5.1295e-04 - val_mse: 5.1295e-04 - val_acc: 0.6204\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 5.6925e-04 - mse: 5.6925e-04 - acc: 0.6401 - val_loss: 4.8959e-04 - val_mse: 4.8959e-04 - val_acc: 0.6275\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 5.4908e-04 - mse: 5.4908e-04 - acc: 0.6481 - val_loss: 5.5032e-04 - val_mse: 5.5032e-04 - val_acc: 0.6382\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 5.3139e-04 - mse: 5.3139e-04 - acc: 0.6460 - val_loss: 4.7003e-04 - val_mse: 4.7003e-04 - val_acc: 0.5875\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 5.2123e-04 - mse: 5.2123e-04 - acc: 0.6493 - val_loss: 4.3853e-04 - val_mse: 4.3853e-04 - val_acc: 0.6434\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 5.1187e-04 - mse: 5.1187e-04 - acc: 0.6449 - val_loss: 4.3981e-04 - val_mse: 4.3981e-04 - val_acc: 0.6386\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 5.0338e-04 - mse: 5.0338e-04 - acc: 0.6470 - val_loss: 4.4029e-04 - val_mse: 4.4029e-04 - val_acc: 0.6337\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 5.0282e-04 - mse: 5.0282e-04 - acc: 0.6507 - val_loss: 7.7993e-04 - val_mse: 7.7993e-04 - val_acc: 0.5801\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.9238e-04 - mse: 4.9238e-04 - acc: 0.6526 - val_loss: 4.6210e-04 - val_mse: 4.6210e-04 - val_acc: 0.6356\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.8973e-04 - mse: 4.8973e-04 - acc: 0.6510 - val_loss: 4.8260e-04 - val_mse: 4.8260e-04 - val_acc: 0.6348\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.8064e-04 - mse: 4.8064e-04 - acc: 0.6526 - val_loss: 4.3057e-04 - val_mse: 4.3057e-04 - val_acc: 0.6389\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.8231e-04 - mse: 4.8231e-04 - acc: 0.6520 - val_loss: 4.3374e-04 - val_mse: 4.3374e-04 - val_acc: 0.5551\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.7586e-04 - mse: 4.7586e-04 - acc: 0.6500 - val_loss: 4.5638e-04 - val_mse: 4.5638e-04 - val_acc: 0.6358\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.6630e-04 - mse: 4.6630e-04 - acc: 0.6512 - val_loss: 4.1821e-04 - val_mse: 4.1821e-04 - val_acc: 0.6350\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.6617e-04 - mse: 4.6617e-04 - acc: 0.6470 - val_loss: 4.7752e-04 - val_mse: 4.7752e-04 - val_acc: 0.6528\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.6522e-04 - mse: 4.6522e-04 - acc: 0.6502 - val_loss: 4.2162e-04 - val_mse: 4.2162e-04 - val_acc: 0.5551\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.5462e-04 - mse: 4.5462e-04 - acc: 0.6502 - val_loss: 4.2466e-04 - val_mse: 4.2466e-04 - val_acc: 0.5814\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.6274e-04 - mse: 4.6274e-04 - acc: 0.6481 - val_loss: 5.0947e-04 - val_mse: 5.0947e-04 - val_acc: 0.6464\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.5927e-04 - mse: 4.5927e-04 - acc: 0.6492 - val_loss: 4.5622e-04 - val_mse: 4.5622e-04 - val_acc: 0.6471\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.5360e-04 - mse: 4.5360e-04 - acc: 0.6461 - val_loss: 4.2405e-04 - val_mse: 4.2405e-04 - val_acc: 0.6488\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.5174e-04 - mse: 4.5174e-04 - acc: 0.6508 - val_loss: 4.5322e-04 - val_mse: 4.5322e-04 - val_acc: 0.6354\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.4598e-04 - mse: 4.4598e-04 - acc: 0.6522 - val_loss: 5.3912e-04 - val_mse: 5.3912e-04 - val_acc: 0.6453\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.4918e-04 - mse: 4.4918e-04 - acc: 0.6533 - val_loss: 5.2899e-04 - val_mse: 5.2899e-04 - val_acc: 0.6369\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.4613e-04 - mse: 4.4613e-04 - acc: 0.6548 - val_loss: 4.4028e-04 - val_mse: 4.4028e-04 - val_acc: 0.6296\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.4174e-04 - mse: 4.4174e-04 - acc: 0.6558 - val_loss: 4.5213e-04 - val_mse: 4.5213e-04 - val_acc: 0.6073\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.4399e-04 - mse: 4.4399e-04 - acc: 0.6545 - val_loss: 4.2429e-04 - val_mse: 4.2429e-04 - val_acc: 0.5890\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 4.4085e-04 - mse: 4.4085e-04 - acc: 0.6591 - val_loss: 4.3917e-04 - val_mse: 4.3917e-04 - val_acc: 0.6489\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, \n\u001b[0;32m      4\u001b[0m           y_train, \n\u001b[0;32m      5\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m           validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     10\u001b[0m           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# save trained model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds-ga1018\\lib\\site-packages\\keras\\engine\\training.py:2145\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;124;03m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[0;32m   2104\u001b[0m \n\u001b[0;32m   2105\u001b[0m \u001b[38;5;124;03mPlease see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2144\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m-> 2145\u001b[0m \u001b[43msave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m                \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_traces\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds-ga1018\\lib\\site-packages\\keras\\saving\\save.py:138\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (save_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     saving_utils\u001b[38;5;241m.\u001b[39mis_hdf5_filepath(filepath)):\n\u001b[0;32m    135\u001b[0m   \u001b[38;5;66;03m# TODO(b/130258301): add utility method for detecting model type.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m  \u001b[38;5;66;03m# pylint:disable=protected-access\u001b[39;00m\n\u001b[0;32m    137\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, sequential\u001b[38;5;241m.\u001b[39mSequential)):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaving the model to HDF5 format requires the model to be a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunctional model or a Sequential model. It does not work for \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubclassed models, because such models are defined via the body of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma Python method, which isn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt safely serializable. Consider saving \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto the Tensorflow SavedModel format (by setting save_format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor using `save_weights`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    145\u001b[0m   hdf5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[0;32m    146\u001b[0m       model, filepath, overwrite, include_optimizer)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n",
    "\n",
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceea1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd0043ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error\n",
      "train set: 0.0004170456633177511\n",
      "test set: 0.00046350849019847714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258ce9b",
   "metadata": {},
   "source": [
    "## input length : output length = 24:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8be2411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 24\n",
    "forecast_len = 6\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "787bb430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM-FC_24-6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 24, 12)]          0         \n",
      "_________________________________________________________________\n",
      "bilstm_1 (Bidirectional)     (None, 60)                10320     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 66        \n",
      "=================================================================\n",
      "Total params: 11,816\n",
      "Trainable params: 11,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM-FC_24-6'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2e8f948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 14s 11ms/step - loss: 0.0024 - mse: 0.0024 - acc: 0.5078 - val_loss: 9.8914e-04 - val_mse: 9.8914e-04 - val_acc: 0.5707\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.2971e-04 - mse: 9.2971e-04 - acc: 0.5834 - val_loss: 9.1004e-04 - val_mse: 9.1004e-04 - val_acc: 0.5799\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 8.6675e-04 - mse: 8.6675e-04 - acc: 0.5963 - val_loss: 8.2922e-04 - val_mse: 8.2922e-04 - val_acc: 0.6037\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 8.1961e-04 - mse: 8.1961e-04 - acc: 0.5977 - val_loss: 9.0506e-04 - val_mse: 9.0506e-04 - val_acc: 0.5154\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 7.8184e-04 - mse: 7.8184e-04 - acc: 0.5967 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5092\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 7.7214e-04 - mse: 7.7214e-04 - acc: 0.5957 - val_loss: 7.8394e-04 - val_mse: 7.8394e-04 - val_acc: 0.5796\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 7.6011e-04 - mse: 7.6011e-04 - acc: 0.5947 - val_loss: 7.0512e-04 - val_mse: 7.0512e-04 - val_acc: 0.5245\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 7.3237e-04 - mse: 7.3237e-04 - acc: 0.5991 - val_loss: 6.6616e-04 - val_mse: 6.6616e-04 - val_acc: 0.5867\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 7.1213e-04 - mse: 7.1213e-04 - acc: 0.6010 - val_loss: 7.8613e-04 - val_mse: 7.8613e-04 - val_acc: 0.5898\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 7.0191e-04 - mse: 7.0191e-04 - acc: 0.6039 - val_loss: 7.0502e-04 - val_mse: 7.0502e-04 - val_acc: 0.5650\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.9409e-04 - mse: 6.9409e-04 - acc: 0.6038 - val_loss: 6.8818e-04 - val_mse: 6.8818e-04 - val_acc: 0.5159\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.8775e-04 - mse: 6.8775e-04 - acc: 0.6096 - val_loss: 8.0007e-04 - val_mse: 8.0007e-04 - val_acc: 0.6229\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 6.7921e-04 - mse: 6.7921e-04 - acc: 0.6092 - val_loss: 6.7706e-04 - val_mse: 6.7706e-04 - val_acc: 0.4947\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.6935e-04 - mse: 6.6935e-04 - acc: 0.6072 - val_loss: 6.8936e-04 - val_mse: 6.8936e-04 - val_acc: 0.6283\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.7036e-04 - mse: 6.7036e-04 - acc: 0.6089 - val_loss: 7.5694e-04 - val_mse: 7.5694e-04 - val_acc: 0.6219\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.6939e-04 - mse: 6.6939e-04 - acc: 0.6104 - val_loss: 6.5765e-04 - val_mse: 6.5765e-04 - val_acc: 0.5015\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 6.4963e-04 - mse: 6.4963e-04 - acc: 0.6087 - val_loss: 6.5970e-04 - val_mse: 6.5970e-04 - val_acc: 0.4858\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 6.5592e-04 - mse: 6.5592e-04 - acc: 0.6084 - val_loss: 7.2990e-04 - val_mse: 7.2990e-04 - val_acc: 0.5537\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 6.4638e-04 - mse: 6.4638e-04 - acc: 0.6098 - val_loss: 6.6524e-04 - val_mse: 6.6524e-04 - val_acc: 0.5901\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 6.4397e-04 - mse: 6.4397e-04 - acc: 0.6098 - val_loss: 6.2401e-04 - val_mse: 6.2401e-04 - val_acc: 0.5777\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.3967e-04 - mse: 6.3967e-04 - acc: 0.6134 - val_loss: 6.8945e-04 - val_mse: 6.8945e-04 - val_acc: 0.5818\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.3351e-04 - mse: 6.3351e-04 - acc: 0.6134 - val_loss: 6.3794e-04 - val_mse: 6.3794e-04 - val_acc: 0.5349\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.4169e-04 - mse: 6.4169e-04 - acc: 0.6090 - val_loss: 6.1433e-04 - val_mse: 6.1433e-04 - val_acc: 0.4525\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 6.2715e-04 - mse: 6.2715e-04 - acc: 0.6131 - val_loss: 6.5366e-04 - val_mse: 6.5366e-04 - val_acc: 0.6004\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 6.2833e-04 - mse: 6.2833e-04 - acc: 0.6077 - val_loss: 6.3122e-04 - val_mse: 6.3122e-04 - val_acc: 0.5929\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.1941e-04 - mse: 6.1941e-04 - acc: 0.6132 - val_loss: 6.1170e-04 - val_mse: 6.1170e-04 - val_acc: 0.5902\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.2256e-04 - mse: 6.2256e-04 - acc: 0.6108 - val_loss: 6.6476e-04 - val_mse: 6.6476e-04 - val_acc: 0.5778\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 6.1633e-04 - mse: 6.1633e-04 - acc: 0.6127 - val_loss: 7.1784e-04 - val_mse: 7.1784e-04 - val_acc: 0.5426\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.2094e-04 - mse: 6.2094e-04 - acc: 0.6117 - val_loss: 6.5083e-04 - val_mse: 6.5083e-04 - val_acc: 0.6136\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 6.5825e-04 - mse: 6.5825e-04 - acc: 0.6067 - val_loss: 8.0707e-04 - val_mse: 8.0707e-04 - val_acc: 0.5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM-FC_24-6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM-FC_24-6\\assets\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n",
    "\n",
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "520fc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error\n",
      "train set: 0.0008283812328358121\n",
      "test set: 0.0008870415146179263\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dbd001",
   "metadata": {},
   "source": [
    "## input length : output length = 32:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86bc5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 32\n",
    "forecast_len = 8\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab4164d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM-FC_32-8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 32, 12)]          0         \n",
      "_________________________________________________________________\n",
      "bilstm_1 (Bidirectional)     (None, 60)                10320     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 88        \n",
      "=================================================================\n",
      "Total params: 11,838\n",
      "Trainable params: 11,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM-FC_32-8'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b571424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 15s 11ms/step - loss: 0.0031 - mse: 0.0031 - acc: 0.2168 - val_loss: 0.0016 - val_mse: 0.0016 - val_acc: 0.5138\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5321 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5335\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5372 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5513\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5364 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5421\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5386 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5037\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5396 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5366\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5403 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5335\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5410 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5440\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5434 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.5060\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5397 - val_loss: 0.0021 - val_mse: 0.0021 - val_acc: 0.5190\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5406 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.5563\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5434 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.4851\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5438 - val_loss: 0.0018 - val_mse: 0.0018 - val_acc: 0.5235\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.9721e-04 - mse: 9.9721e-04 - acc: 0.5426 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.5632\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.8263e-04 - mse: 9.8263e-04 - acc: 0.5421 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.5352\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.7495e-04 - mse: 9.7495e-04 - acc: 0.5450 - val_loss: 0.0023 - val_mse: 0.0023 - val_acc: 0.5567\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.7147e-04 - mse: 9.7147e-04 - acc: 0.5433 - val_loss: 0.0022 - val_mse: 0.0022 - val_acc: 0.5609\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.6304e-04 - mse: 9.6304e-04 - acc: 0.5432 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.5348\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.5101e-04 - mse: 9.5101e-04 - acc: 0.5452 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.5297\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.4150e-04 - mse: 9.4150e-04 - acc: 0.5482 - val_loss: 0.0022 - val_mse: 0.0022 - val_acc: 0.4815\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.4633e-04 - mse: 9.4633e-04 - acc: 0.5428 - val_loss: 0.0021 - val_mse: 0.0021 - val_acc: 0.4413\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 9.4084e-04 - mse: 9.4084e-04 - acc: 0.5440 - val_loss: 0.0021 - val_mse: 0.0021 - val_acc: 0.5444\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 9.2964e-04 - mse: 9.2964e-04 - acc: 0.5470 - val_loss: 0.0021 - val_mse: 0.0021 - val_acc: 0.5582\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.2858e-04 - mse: 9.2858e-04 - acc: 0.5432 - val_loss: 0.0021 - val_mse: 0.0021 - val_acc: 0.5368\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.2275e-04 - mse: 9.2275e-04 - acc: 0.5433 - val_loss: 0.0018 - val_mse: 0.0018 - val_acc: 0.5352\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.2070e-04 - mse: 9.2070e-04 - acc: 0.5450 - val_loss: 0.0022 - val_mse: 0.0022 - val_acc: 0.5256\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 9.1879e-04 - mse: 9.1879e-04 - acc: 0.5443 - val_loss: 0.0020 - val_mse: 0.0020 - val_acc: 0.5511\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.0914e-04 - mse: 9.0914e-04 - acc: 0.5457 - val_loss: 0.0018 - val_mse: 0.0018 - val_acc: 0.5243\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.1380e-04 - mse: 9.1380e-04 - acc: 0.5438 - val_loss: 0.0018 - val_mse: 0.0018 - val_acc: 0.4886\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 9.0927e-04 - mse: 9.0927e-04 - acc: 0.5463 - val_loss: 0.0021 - val_mse: 0.0021 - val_acc: 0.5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM-FC_32-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM-FC_32-8\\assets\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n",
    "\n",
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed47bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error\n",
      "train set: 0.0010155419822062816\n",
      "test set: 0.0009935785992626514\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e0a20",
   "metadata": {},
   "source": [
    "## input length : output length = 40:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c9521fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 40\n",
    "forecast_len = 10\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2091b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM-FC_40-10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 40, 12)]          0         \n",
      "_________________________________________________________________\n",
      "bilstm_1 (Bidirectional)     (None, 60)                10320     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 11,860\n",
      "Trainable params: 11,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM-FC_40-10'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2de6ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 14s 11ms/step - loss: 0.0043 - mse: 0.0043 - acc: 0.3658 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.2045\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0015 - mse: 0.0015 - acc: 0.4855 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4850\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0014 - mse: 0.0014 - acc: 0.4999 - val_loss: 0.0016 - val_mse: 0.0016 - val_acc: 0.4123\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0014 - mse: 0.0014 - acc: 0.5021 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4511\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5093 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5242\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5076 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5161\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5101 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4408\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5111 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4782\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5150 - val_loss: 0.0017 - val_mse: 0.0017 - val_acc: 0.4608\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5159 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5142\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5158 - val_loss: 0.0018 - val_mse: 0.0018 - val_acc: 0.3737\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5155 - val_loss: 0.0019 - val_mse: 0.0019 - val_acc: 0.4002\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5170 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5402\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5170 - val_loss: 0.0016 - val_mse: 0.0016 - val_acc: 0.5037\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5173 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4655\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5168 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.4250\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5163 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4904\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5177 - val_loss: 0.0021 - val_mse: 0.0021 - val_acc: 0.5392\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5182 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5408\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5188 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5269\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5187 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4652\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5191 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5052\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5182 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5031\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5181 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4962\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5204 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4631\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5195 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5297\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5200 - val_loss: 0.0018 - val_mse: 0.0018 - val_acc: 0.4919\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 13s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5207 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4367\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5207 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5174\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5191 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM-FC_40-10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM-FC_40-10\\assets\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n",
    "\n",
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "881a1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error\n",
      "train set: 0.001098032455478074\n",
      "test set: 0.0012681936393976359\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
