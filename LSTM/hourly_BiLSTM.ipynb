{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3788ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ec7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "WARNING:tensorflow:From C:\\Users\\dujy0\\AppData\\Local\\Temp\\ipykernel_39948\\4004085722.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "\n",
      "CUDA GPU: False\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB=True\n",
    "except:\n",
    "    IN_COLAB=False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"We're running Colab\")\n",
    "else:\n",
    "    print(tf.config.list_physical_devices())\n",
    "    print('\\nCUDA GPU: ' + str(tf.test.is_gpu_available(cuda_only=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ebbfa",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825068e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "df = pd.read_csv('./hourly02-ithaca/hourly02-NY_Ithaca_13_E.csv', header = 0, index_col = 0)\n",
    "Date = pd.to_datetime(df.UTC_DATE, format='%Y%m%d', errors='coerce')\n",
    "+ pd.to_timedelta(df.UTC_TIME//100, unit = 'hours')\n",
    "df['Time'] = Date\n",
    "data = df[['T_CALC', 'T_HR_AVG', 'T_MAX', 'T_MIN',\n",
    "       'P_CALC', 'SOLARAD', 'SOLARAD_MAX',\n",
    "       'SOLARAD_MIN', 'SUR_TEMP',\n",
    "           'SUR_TEMP_MAX', 'SUR_TEMP_MIN', 'RH_HR_AVG']]\n",
    "data.index = df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b1a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_CALC           1384\n",
       "T_HR_AVG         1446\n",
       "T_MAX            1385\n",
       "T_MIN            1389\n",
       "P_CALC            832\n",
       "SOLARAD           570\n",
       "SOLARAD_MAX      9757\n",
       "SOLARAD_MIN      9757\n",
       "SUR_TEMP          724\n",
       "SUR_TEMP_MAX     9911\n",
       "SUR_TEMP_MIN     9911\n",
       "RH_HR_AVG       48248\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98be58ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166759, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d169f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill the missing values  \n",
    "data.ffill(axis = 0, inplace = True)\n",
    "# drop NaN at the top\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ba21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target\n",
    "data['target'] = data['T_HR_AVG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6a51031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597b6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "with open('./LSTM/models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba1ac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126057, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf181b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31515, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ce69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into sequences\n",
    "def split_sequences(features, target, seq_len, forecast_len):\n",
    "    X,y = list(), list()\n",
    "    for i in range(len(features)):\n",
    "        end_input = i + seq_len\n",
    "        end_predict = end_input + forecast_len\n",
    "        if end_predict > len(features)-1:\n",
    "            break\n",
    "        seq_x, seq_y = features[i:end_input,:], target[end_input:end_predict]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return tf.convert_to_tensor(X, dtype=tf.float64), tf.convert_to_tensor(y, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc7e6b",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e46daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RNN, LSTMCell, Input, Bidirectional\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape, hidden_unit = 30, activation_type = 'tanh', name = 'BiLSTM'):\n",
    "        super().__init__(name = name)\n",
    "        self.input_layer = Input(shape = input_shape, name = 'input')\n",
    "        self.lstm1 = Bidirectional(LSTM(units=hidden_unit, activation = activation_type, input_shape = input_shape, return_sequences=False, name = 'lstm_1'), name = 'bilstm_1')\n",
    "        self.dense1 = Dense(units=output_shape, activation = 'sigmoid', name = 'dense_1')\n",
    "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.lstm1(inputs)\n",
    "        x = self.dense1(x)\n",
    "        #if training:\n",
    "        #  x = self.dropout(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def summary(self):\n",
    "        model = Model(inputs = [self.input_layer], outputs = self.call(self.input_layer), name = self.name)\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28807bc6",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "## input length : output length = 16:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ec4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequences\n",
    "seq_len = 16\n",
    "forecast_len = 4\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c26eaa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([126037, 16, 12])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "039bed2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([126037, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f03c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM_16-4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 16, 12)]          0         \n",
      "                                                                 \n",
      " bilstm_1 (Bidirectional)    (None, 60)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 244       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,564\n",
      "Trainable params: 10,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM_16-4'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06942327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 9s 6ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5727 - val_loss: 5.4724e-04 - val_mse: 5.4724e-04 - val_acc: 0.5736\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 5.8210e-04 - mse: 5.8210e-04 - acc: 0.6293 - val_loss: 4.9174e-04 - val_mse: 4.9174e-04 - val_acc: 0.6262\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 6s 6ms/step - loss: 5.3807e-04 - mse: 5.3807e-04 - acc: 0.6426 - val_loss: 4.9200e-04 - val_mse: 4.9200e-04 - val_acc: 0.5632\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 5.1388e-04 - mse: 5.1388e-04 - acc: 0.6487 - val_loss: 4.6915e-04 - val_mse: 4.6915e-04 - val_acc: 0.6063\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.9851e-04 - mse: 4.9851e-04 - acc: 0.6524 - val_loss: 4.7251e-04 - val_mse: 4.7251e-04 - val_acc: 0.6420\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.8966e-04 - mse: 4.8966e-04 - acc: 0.6555 - val_loss: 4.6682e-04 - val_mse: 4.6682e-04 - val_acc: 0.6051\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.7340e-04 - mse: 4.7340e-04 - acc: 0.6603 - val_loss: 4.6996e-04 - val_mse: 4.6996e-04 - val_acc: 0.6265\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.6750e-04 - mse: 4.6750e-04 - acc: 0.6613 - val_loss: 4.2455e-04 - val_mse: 4.2455e-04 - val_acc: 0.6432\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.6002e-04 - mse: 4.6002e-04 - acc: 0.6634 - val_loss: 4.3701e-04 - val_mse: 4.3701e-04 - val_acc: 0.6584\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.5673e-04 - mse: 4.5673e-04 - acc: 0.6650 - val_loss: 4.4556e-04 - val_mse: 4.4556e-04 - val_acc: 0.6398\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.4989e-04 - mse: 4.4989e-04 - acc: 0.6668 - val_loss: 4.1449e-04 - val_mse: 4.1449e-04 - val_acc: 0.6438\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.4500e-04 - mse: 4.4500e-04 - acc: 0.6666 - val_loss: 4.1437e-04 - val_mse: 4.1437e-04 - val_acc: 0.6490\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.4203e-04 - mse: 4.4203e-04 - acc: 0.6690 - val_loss: 4.5156e-04 - val_mse: 4.5156e-04 - val_acc: 0.5981\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.4157e-04 - mse: 4.4157e-04 - acc: 0.6696 - val_loss: 4.0535e-04 - val_mse: 4.0535e-04 - val_acc: 0.6473\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.3270e-04 - mse: 4.3270e-04 - acc: 0.6687 - val_loss: 4.5302e-04 - val_mse: 4.5302e-04 - val_acc: 0.6520\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.3203e-04 - mse: 4.3203e-04 - acc: 0.6697 - val_loss: 4.2254e-04 - val_mse: 4.2254e-04 - val_acc: 0.6219\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.2879e-04 - mse: 4.2879e-04 - acc: 0.6698 - val_loss: 4.0865e-04 - val_mse: 4.0865e-04 - val_acc: 0.6555\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 7s 7ms/step - loss: 4.2470e-04 - mse: 4.2470e-04 - acc: 0.6694 - val_loss: 4.1365e-04 - val_mse: 4.1365e-04 - val_acc: 0.6480\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.2356e-04 - mse: 4.2356e-04 - acc: 0.6715 - val_loss: 4.2079e-04 - val_mse: 4.2079e-04 - val_acc: 0.6143\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.1951e-04 - mse: 4.1951e-04 - acc: 0.6731 - val_loss: 4.5185e-04 - val_mse: 4.5185e-04 - val_acc: 0.6500\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.1800e-04 - mse: 4.1800e-04 - acc: 0.6723 - val_loss: 4.1895e-04 - val_mse: 4.1895e-04 - val_acc: 0.6417\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.1762e-04 - mse: 4.1762e-04 - acc: 0.6726 - val_loss: 4.1131e-04 - val_mse: 4.1131e-04 - val_acc: 0.6307\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.1566e-04 - mse: 4.1566e-04 - acc: 0.6744 - val_loss: 4.4153e-04 - val_mse: 4.4153e-04 - val_acc: 0.6402\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.1293e-04 - mse: 4.1293e-04 - acc: 0.6743 - val_loss: 4.2473e-04 - val_mse: 4.2473e-04 - val_acc: 0.6513\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 7s 7ms/step - loss: 4.1081e-04 - mse: 4.1081e-04 - acc: 0.6740 - val_loss: 4.2881e-04 - val_mse: 4.2881e-04 - val_acc: 0.6342\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 4.0749e-04 - mse: 4.0749e-04 - acc: 0.6751 - val_loss: 4.2917e-04 - val_mse: 4.2917e-04 - val_acc: 0.6430\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 7s 7ms/step - loss: 4.0796e-04 - mse: 4.0796e-04 - acc: 0.6744 - val_loss: 4.3882e-04 - val_mse: 4.3882e-04 - val_acc: 0.6265\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 7s 6ms/step - loss: 4.0753e-04 - mse: 4.0753e-04 - acc: 0.6761 - val_loss: 4.1081e-04 - val_mse: 4.1081e-04 - val_acc: 0.6269\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 7s 7ms/step - loss: 4.0408e-04 - mse: 4.0408e-04 - acc: 0.6743 - val_loss: 4.4652e-04 - val_mse: 4.4652e-04 - val_acc: 0.6526\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 8s 7ms/step - loss: 4.0380e-04 - mse: 4.0380e-04 - acc: 0.6744 - val_loss: 4.1531e-04 - val_mse: 4.1531e-04 - val_acc: 0.6294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237a8df77c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceea1dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM_16-4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM_16-4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3939/3939 [==============================] - 5s 1ms/step\n",
      "985/985 [==============================] - 1s 1ms/step\n",
      "mean_squared_error\n",
      "train set: 0.000393290856248061\n",
      "test set: 0.0004359774272130303\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258ce9b",
   "metadata": {},
   "source": [
    "## input length : output length = 24:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8be2411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 24\n",
    "forecast_len = 6\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "787bb430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM_24-6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 24, 12)]          0         \n",
      "                                                                 \n",
      " bilstm_1 (Bidirectional)    (None, 60)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 366       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,686\n",
      "Trainable params: 10,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM_24-6'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2e8f948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 14s 10ms/step - loss: 0.0014 - mse: 0.0014 - acc: 0.5455 - val_loss: 8.8443e-04 - val_mse: 8.8443e-04 - val_acc: 0.5704\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 9s 8ms/step - loss: 8.3685e-04 - mse: 8.3685e-04 - acc: 0.5890 - val_loss: 9.3538e-04 - val_mse: 9.3538e-04 - val_acc: 0.4488\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 7.7153e-04 - mse: 7.7153e-04 - acc: 0.6030 - val_loss: 9.5088e-04 - val_mse: 9.5088e-04 - val_acc: 0.5700\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 7.3620e-04 - mse: 7.3620e-04 - acc: 0.6100 - val_loss: 9.2715e-04 - val_mse: 9.2715e-04 - val_acc: 0.6086\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 7.1377e-04 - mse: 7.1377e-04 - acc: 0.6138 - val_loss: 7.0248e-04 - val_mse: 7.0248e-04 - val_acc: 0.5055\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 6.9290e-04 - mse: 6.9290e-04 - acc: 0.6157 - val_loss: 6.8939e-04 - val_mse: 6.8939e-04 - val_acc: 0.6046\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 9s 8ms/step - loss: 6.8213e-04 - mse: 6.8213e-04 - acc: 0.6174 - val_loss: 7.1387e-04 - val_mse: 7.1387e-04 - val_acc: 0.6035\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 6.6812e-04 - mse: 6.6812e-04 - acc: 0.6165 - val_loss: 6.6767e-04 - val_mse: 6.6767e-04 - val_acc: 0.5761\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 6.6261e-04 - mse: 6.6261e-04 - acc: 0.6199 - val_loss: 6.9006e-04 - val_mse: 6.9006e-04 - val_acc: 0.6077\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 6.4687e-04 - mse: 6.4687e-04 - acc: 0.6210 - val_loss: 6.5547e-04 - val_mse: 6.5547e-04 - val_acc: 0.5248\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 6.4729e-04 - mse: 6.4729e-04 - acc: 0.6198 - val_loss: 7.7305e-04 - val_mse: 7.7305e-04 - val_acc: 0.5675\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 6.3584e-04 - mse: 6.3584e-04 - acc: 0.6211 - val_loss: 6.7186e-04 - val_mse: 6.7186e-04 - val_acc: 0.5411\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 10s 8ms/step - loss: 6.2898e-04 - mse: 6.2898e-04 - acc: 0.6245 - val_loss: 6.7584e-04 - val_mse: 6.7584e-04 - val_acc: 0.5999\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 6.2131e-04 - mse: 6.2131e-04 - acc: 0.6221 - val_loss: 6.9027e-04 - val_mse: 6.9027e-04 - val_acc: 0.5930\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 6.1685e-04 - mse: 6.1685e-04 - acc: 0.6237 - val_loss: 6.3624e-04 - val_mse: 6.3624e-04 - val_acc: 0.5966\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 6.1484e-04 - mse: 6.1484e-04 - acc: 0.6254 - val_loss: 6.3478e-04 - val_mse: 6.3478e-04 - val_acc: 0.5971\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 6.0691e-04 - mse: 6.0691e-04 - acc: 0.6248 - val_loss: 7.8512e-04 - val_mse: 7.8512e-04 - val_acc: 0.5209\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 6.0540e-04 - mse: 6.0540e-04 - acc: 0.6260 - val_loss: 6.8726e-04 - val_mse: 6.8726e-04 - val_acc: 0.5903\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 6.0063e-04 - mse: 6.0063e-04 - acc: 0.6257 - val_loss: 6.4926e-04 - val_mse: 6.4926e-04 - val_acc: 0.5853\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 6.0442e-04 - mse: 6.0442e-04 - acc: 0.6267 - val_loss: 6.1072e-04 - val_mse: 6.1072e-04 - val_acc: 0.5543\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.9226e-04 - mse: 5.9226e-04 - acc: 0.6261 - val_loss: 6.3576e-04 - val_mse: 6.3576e-04 - val_acc: 0.5389\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.8942e-04 - mse: 5.8942e-04 - acc: 0.6273 - val_loss: 6.1434e-04 - val_mse: 6.1434e-04 - val_acc: 0.6087\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.8895e-04 - mse: 5.8895e-04 - acc: 0.6293 - val_loss: 6.1977e-04 - val_mse: 6.1977e-04 - val_acc: 0.5960\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.8553e-04 - mse: 5.8553e-04 - acc: 0.6294 - val_loss: 6.4968e-04 - val_mse: 6.4968e-04 - val_acc: 0.5938\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.8306e-04 - mse: 5.8306e-04 - acc: 0.6288 - val_loss: 6.1473e-04 - val_mse: 6.1473e-04 - val_acc: 0.5891\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.8014e-04 - mse: 5.8014e-04 - acc: 0.6271 - val_loss: 6.3703e-04 - val_mse: 6.3703e-04 - val_acc: 0.5500\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.7722e-04 - mse: 5.7722e-04 - acc: 0.6292 - val_loss: 6.8205e-04 - val_mse: 6.8205e-04 - val_acc: 0.5960\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.7524e-04 - mse: 5.7524e-04 - acc: 0.6315 - val_loss: 6.3565e-04 - val_mse: 6.3565e-04 - val_acc: 0.5980\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.7305e-04 - mse: 5.7305e-04 - acc: 0.6328 - val_loss: 6.3584e-04 - val_mse: 6.3584e-04 - val_acc: 0.6026\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 10s 9ms/step - loss: 5.7504e-04 - mse: 5.7504e-04 - acc: 0.6314 - val_loss: 6.3003e-04 - val_mse: 6.3003e-04 - val_acc: 0.5960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237f2d1cfa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "520fc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM_24-6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM_24-6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3939/3939 [==============================] - 6s 1ms/step\n",
      "984/984 [==============================] - 1s 1ms/step\n",
      "mean_squared_error\n",
      "train set: 0.0005670177831102061\n",
      "test set: 0.0006549832945472625\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)\n",
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dbd001",
   "metadata": {},
   "source": [
    "## input length : output length = 32:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86bc5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 32\n",
    "forecast_len = 8\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab4164d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM_32-8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 32, 12)]          0         \n",
      "                                                                 \n",
      " bilstm_1 (Bidirectional)    (None, 60)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 488       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,808\n",
      "Trainable params: 10,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM_32-8'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b571424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 14s 11ms/step - loss: 0.0019 - mse: 0.0019 - acc: 0.5011 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.4676\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5412 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5240\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5546 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5472\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 11s 10ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5600 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5523\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 9.8514e-04 - mse: 9.8514e-04 - acc: 0.5641 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5306\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 9.6318e-04 - mse: 9.6318e-04 - acc: 0.5673 - val_loss: 0.0011 - val_mse: 0.0011 - val_acc: 0.5655\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 9.3260e-04 - mse: 9.3260e-04 - acc: 0.5693 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5360\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 9.2208e-04 - mse: 9.2208e-04 - acc: 0.5719 - val_loss: 0.0012 - val_mse: 0.0012 - val_acc: 0.5516\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 9.1305e-04 - mse: 9.1305e-04 - acc: 0.5720 - val_loss: 9.5502e-04 - val_mse: 9.5502e-04 - val_acc: 0.4841\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.9288e-04 - mse: 8.9288e-04 - acc: 0.5770 - val_loss: 9.4056e-04 - val_mse: 9.4056e-04 - val_acc: 0.5352\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.8107e-04 - mse: 8.8107e-04 - acc: 0.5788 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5432\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.7737e-04 - mse: 8.7737e-04 - acc: 0.5767 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5651\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 8.6808e-04 - mse: 8.6808e-04 - acc: 0.5790 - val_loss: 9.3983e-04 - val_mse: 9.3983e-04 - val_acc: 0.5542\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 12s 11ms/step - loss: 8.6707e-04 - mse: 8.6707e-04 - acc: 0.5782 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5467\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.5430e-04 - mse: 8.5430e-04 - acc: 0.5808 - val_loss: 9.1610e-04 - val_mse: 9.1610e-04 - val_acc: 0.5477\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.4886e-04 - mse: 8.4886e-04 - acc: 0.5820 - val_loss: 9.1746e-04 - val_mse: 9.1746e-04 - val_acc: 0.5459\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.3701e-04 - mse: 8.3701e-04 - acc: 0.5793 - val_loss: 8.8215e-04 - val_mse: 8.8215e-04 - val_acc: 0.5538\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.3454e-04 - mse: 8.3454e-04 - acc: 0.5819 - val_loss: 8.8847e-04 - val_mse: 8.8847e-04 - val_acc: 0.5636\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.3190e-04 - mse: 8.3190e-04 - acc: 0.5813 - val_loss: 9.7648e-04 - val_mse: 9.7648e-04 - val_acc: 0.4917\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.2544e-04 - mse: 8.2544e-04 - acc: 0.5818 - val_loss: 9.2105e-04 - val_mse: 9.2105e-04 - val_acc: 0.5441\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.2714e-04 - mse: 8.2714e-04 - acc: 0.5819 - val_loss: 9.3061e-04 - val_mse: 9.3061e-04 - val_acc: 0.5549\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.1904e-04 - mse: 8.1904e-04 - acc: 0.5815 - val_loss: 9.5991e-04 - val_mse: 9.5991e-04 - val_acc: 0.5348\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.1425e-04 - mse: 8.1425e-04 - acc: 0.5832 - val_loss: 0.0010 - val_mse: 0.0010 - val_acc: 0.5084\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.0873e-04 - mse: 8.0873e-04 - acc: 0.5828 - val_loss: 8.9366e-04 - val_mse: 8.9366e-04 - val_acc: 0.5598\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.1022e-04 - mse: 8.1022e-04 - acc: 0.5835 - val_loss: 9.1659e-04 - val_mse: 9.1659e-04 - val_acc: 0.5632\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 8.0268e-04 - mse: 8.0268e-04 - acc: 0.5827 - val_loss: 8.8164e-04 - val_mse: 8.8164e-04 - val_acc: 0.5537\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 7.9999e-04 - mse: 7.9999e-04 - acc: 0.5820 - val_loss: 9.1958e-04 - val_mse: 9.1958e-04 - val_acc: 0.5431\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 7.9573e-04 - mse: 7.9573e-04 - acc: 0.5809 - val_loss: 9.2569e-04 - val_mse: 9.2569e-04 - val_acc: 0.5413\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 7.9335e-04 - mse: 7.9335e-04 - acc: 0.5815 - val_loss: 9.1428e-04 - val_mse: 9.1428e-04 - val_acc: 0.5536\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 12s 10ms/step - loss: 7.8782e-04 - mse: 7.8782e-04 - acc: 0.5827 - val_loss: 9.1998e-04 - val_mse: 9.1998e-04 - val_acc: 0.5586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237f263bd60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed47bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM_32-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM_32-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3939/3939 [==============================] - 7s 2ms/step\n",
      "984/984 [==============================] - 2s 2ms/step\n",
      "mean_squared_error\n",
      "train set: 0.0008149588978308926\n",
      "test set: 0.0009227961871954862\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)\n",
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e0a20",
   "metadata": {},
   "source": [
    "## input length : output length = 40:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c9521fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset memory\n",
    "tf.Graph().as_default() \n",
    "\n",
    "# prepare sequences\n",
    "seq_len = 40\n",
    "forecast_len = 10\n",
    "X_train, y_train = split_sequences(train[:,:-1], train[:,-1], seq_len = seq_len, forecast_len = forecast_len)\n",
    "X_test, y_test = split_sequences(test[:,:-1], test[:,-1],seq_len = seq_len, forecast_len =  forecast_len)\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2091b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM_40-10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 40, 12)]          0         \n",
      "                                                                 \n",
      " bilstm_1 (Bidirectional)    (None, 60)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                610       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,930\n",
      "Trainable params: 10,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "model_name = 'BiLSTM_40-10'\n",
    "model = MyModel(input_shape = (seq_len, n_features), output_shape = (forecast_len), name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2de6ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1135/1135 [==============================] - 17s 13ms/step - loss: 0.0021 - mse: 0.0021 - acc: 0.4765 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.4831\n",
      "Epoch 2/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0014 - mse: 0.0014 - acc: 0.5140 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4997\n",
      "Epoch 3/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5183 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5265\n",
      "Epoch 4/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0013 - mse: 0.0013 - acc: 0.5238 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5196\n",
      "Epoch 5/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5250 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4927\n",
      "Epoch 6/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5279 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5208\n",
      "Epoch 7/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0012 - mse: 0.0012 - acc: 0.5290 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5078\n",
      "Epoch 8/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5324 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5187\n",
      "Epoch 9/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5307 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5298\n",
      "Epoch 10/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5346 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4956\n",
      "Epoch 11/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5345 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.4978\n",
      "Epoch 12/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5349 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5150\n",
      "Epoch 13/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5356 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5046\n",
      "Epoch 14/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0011 - mse: 0.0011 - acc: 0.5352 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4932\n",
      "Epoch 15/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5377 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5023\n",
      "Epoch 16/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5378 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.4920\n",
      "Epoch 17/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5379 - val_loss: 0.0013 - val_mse: 0.0013 - val_acc: 0.5065\n",
      "Epoch 18/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5380 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.4938\n",
      "Epoch 19/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5380 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5199\n",
      "Epoch 20/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5405 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5319\n",
      "Epoch 21/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5397 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4566\n",
      "Epoch 22/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 0.0010 - mse: 0.0010 - acc: 0.5395 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5073\n",
      "Epoch 23/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 9.9725e-04 - mse: 9.9725e-04 - acc: 0.5395 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5015\n",
      "Epoch 24/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 9.9259e-04 - mse: 9.9259e-04 - acc: 0.5414 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5060\n",
      "Epoch 25/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 9.8424e-04 - mse: 9.8424e-04 - acc: 0.5425 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.5085\n",
      "Epoch 26/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 9.8336e-04 - mse: 9.8336e-04 - acc: 0.5414 - val_loss: 0.0016 - val_mse: 0.0016 - val_acc: 0.5061\n",
      "Epoch 27/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 9.7856e-04 - mse: 9.7856e-04 - acc: 0.5430 - val_loss: 0.0014 - val_mse: 0.0014 - val_acc: 0.4913\n",
      "Epoch 28/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 9.6938e-04 - mse: 9.6938e-04 - acc: 0.5406 - val_loss: 0.0016 - val_mse: 0.0016 - val_acc: 0.4854\n",
      "Epoch 29/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 9.6643e-04 - mse: 9.6643e-04 - acc: 0.5412 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.4907\n",
      "Epoch 30/30\n",
      "1135/1135 [==============================] - 14s 12ms/step - loss: 9.6679e-04 - mse: 9.6679e-04 - acc: 0.5439 - val_loss: 0.0015 - val_mse: 0.0015 - val_acc: 0.5003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237f1de8850>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate = 0.01), metrics = ['mse', 'acc'])\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=100,\n",
    "          epochs=30,\n",
    "          verbose='auto',\n",
    "          callbacks=None,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "881a1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM_40-10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM/models/BiLSTM_40-10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3938/3938 [==============================] - 9s 2ms/step\n",
      "984/984 [==============================] - 2s 2ms/step\n",
      "mean_squared_error\n",
      "train set: 0.0010243174063823885\n",
      "test set: 0.0011515796027563208\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "model.save('./LSTM/models/' + model_name)\n",
    "# evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error')\n",
    "print('train set:', mean_squared_error(y_train, y_hat_train, sample_weight=None))\n",
    "print('test set:', mean_squared_error(y_test, y_hat_test, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c5a73-c40f-4b16-bef3-463526a7798f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
